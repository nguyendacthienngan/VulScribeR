{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1653,
     "status": "ok",
     "timestamp": 1743577971736,
     "user": {
      "displayName": "Thien Ngan",
      "userId": "09935523481613786802"
     },
     "user_tz": -420
    },
    "id": "gcH3D1HUP6a-",
    "outputId": "8728a4ea-1945-44b8-8ce1-ffb276acd64c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1743577971764,
     "user": {
      "displayName": "Thien Ngan",
      "userId": "09935523481613786802"
     },
     "user_tz": -420
    },
    "id": "HuU1COnvlRKA",
    "outputId": "34514cb4-83aa-491b-aff3-78c04f8b3b84"
   },
   "outputs": [],
   "source": [
    "# %cd /content/drive/MyDrive/GRAD/Thesis/MAPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1743577971813,
     "user": {
      "displayName": "Thien Ngan",
      "userId": "09935523481613786802"
     },
     "user_tz": -420
    },
    "id": "XceB4wDSlSCV",
    "outputId": "fd26c2f3-45d6-44c9-fa86-02969870390d"
   },
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.21\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "d4aYqoTIfRzi"
   },
   "outputs": [],
   "source": [
    "#Load the LLM and the MEGAVUL's train dataframe\n",
    "import json\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = r\"C:\\Users\\Administrator\\Downloads\\VulScribeR-20250404T140824Z-001\\VulScribeR\\code\\megavul_simple.json\"\n",
    "# vul_output_file = r\"/content/drive/MyDrive/GRAD/Thesis/MAPR/megavul_vul.json\"\n",
    "# clean_output_file = r\"/content/drive/MyDrive/GRAD/Thesis/MAPR/megavul_clean.json\"\n",
    "\n",
    "# Set the chunk size (adjust as needed)\n",
    "chunksize = 10000\n",
    "\n",
    "# Create empty lists to store data for each category\n",
    "vul_data = []\n",
    "clean_data = []\n",
    "\n",
    "# Read the JSON file in chunks\n",
    "# for chunk in pd.read_json(input_file, lines=True, chunksize=chunksize):\n",
    "#     # Separate data based on 'is_vul'\n",
    "#     print(chunk)\n",
    "#     vul_chunk = chunk[chunk['is_vul'] == True]\n",
    "#     clean_chunk = chunk[chunk['is_vul'] == False]\n",
    "\n",
    "#     # Append data to the respective lists\n",
    "#     vul_data.extend(vul_chunk.to_dict('records'))\n",
    "#     clean_data.extend(clean_chunk.to_dict('records'))\n",
    "#     gc.collect()  # Run garbage collection\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "mega_vul_df = pd.DataFrame(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "kaFgo-c4zCDo"
   },
   "outputs": [],
   "source": [
    "\n",
    "vul_df = mega_vul_df[mega_vul_df['is_vul'] == True]\n",
    "clean_df = mega_vul_df[mega_vul_df['is_vul'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36349,
     "status": "ok",
     "timestamp": 1743578037800,
     "user": {
      "displayName": "Thien Ngan",
      "userId": "09935523481613786802"
     },
     "user_tz": -420
    },
    "id": "oiFZBzJqPvhY",
    "outputId": "6e0676e9-7a87-4e7d-cd36-4fc40e835473"
   },
   "outputs": [],
   "source": [
    "# # !wget https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
    "# !wget https://repo.anaconda.com/miniconda/Miniconda3-py39_23.9.0-0-Linux-x86_64.sh\n",
    "# !chmod +x Miniconda3-py39_23.9.0-0-Linux-x86_64.sh\n",
    "# !./Miniconda3-py39_23.9.0-0-Linux-x86_64.sh -b -f -p /usr/local\n",
    "# !conda update conda -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ivKpFA6xPluN"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230929,
     "status": "ok",
     "timestamp": 1743578268847,
     "user": {
      "displayName": "Thien Ngan",
      "userId": "09935523481613786802"
     },
     "user_tz": -420
    },
    "id": "Trgx8dRFPkTs",
    "outputId": "20dce11b-5ae7-425f-e5ce-15335d868e6a"
   },
   "outputs": [],
   "source": [
    "\n",
    "# !conda create --name vulscriber-cluster-env python=3.8 -y\n",
    "# !conda activate vulscriber-cluster-env\n",
    "# !conda install pytorch==1.10.0 torchvision==0.11.1 torchaudio==0.10.0 cudatoolkit=11.3 -c pytorch -y\n",
    "# !pip install transformers>4.37.0 pandas scikit-learn accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !conda create --name vulscriber-cluster-env1 python=3.9 -y\n",
    "# !conda activate vulscriber-cluster-env1\n",
    "# !conda install pytorch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1  pytorch-cuda=11.8 -c pytorch -c nvidia -y\n",
    "# !conda install transformers>4.37.0 pandas scikit-learn -y\n",
    "# !conda install conda-forge::accelerate -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install conda-forge::accelerate -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18_p2GQTUf8j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "14u7fQZvPkTt"
   },
   "outputs": [],
   "source": [
    "# !pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3972,
     "status": "ok",
     "timestamp": 1743578272872,
     "user": {
      "displayName": "Thien Ngan",
      "userId": "09935523481613786802"
     },
     "user_tz": -420
    },
    "id": "9epmXKmwPkTt",
    "outputId": "0fbf027d-4f37-4929-d368-1066a04640f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3060\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should print: True\n",
    "print(torch.cuda.device_count())  # Should print: 1\n",
    "print(torch.cuda.get_device_name(0))  # Should print: NVIDIA GeForce RTX 3060\n",
    "print(torch.cuda.current_device())  # Should print 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "dglXd73VUnyj"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List\n",
    "\n",
    "# Define the classes to match the JSON structure\n",
    "\n",
    "\n",
    "class ScoredCodeSnippet:\n",
    "    def __init__(self, id: str, body: str, header: str, score: float, cluster: int):\n",
    "        self.id = id\n",
    "        self.body = body\n",
    "        self.header = header\n",
    "        self.score = score\n",
    "        self.cluster = cluster\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"ScoredCodeSnippet(id='{self.id}', \"\n",
    "                # Print only the first 60 characters of the body for brevity\n",
    "                f\"body='{self.body[:60]}...', \"\n",
    "                f\"header='{self.header}', \"\n",
    "                f\"cluster='{self.cluster}', \"\n",
    "                f\"score={self.score})\")\n",
    "\n",
    "\n",
    "class SearchItem:\n",
    "    def __init__(self, searchItemId: str, scoredCodeSnippets: List[ScoredCodeSnippet]):\n",
    "        self.searchItemId = searchItemId\n",
    "        self.scoredCodeSnippets = scoredCodeSnippets\n",
    "        self.best, self.max_score, self.avg_score = self.__find_max(scoredCodeSnippets)\n",
    "\n",
    "    def __find_max(self, snippets: List[ScoredCodeSnippet]):\n",
    "        avg = 0\n",
    "        max_score = -1\n",
    "        best_match = None\n",
    "        for snippet in snippets:\n",
    "            avg += snippet.score /len(snippets)\n",
    "            if snippet.score > max_score:\n",
    "                max_score = snippet.score\n",
    "                best_match = snippet.id\n",
    "        return best_match, max_score, avg\n",
    "\n",
    "    def get_flattened(self):\n",
    "        items = []\n",
    "        for snippet in self.scoredCodeSnippets:\n",
    "            newItem = SearchItem(self.searchItemId, [snippet])\n",
    "            items.append(newItem)\n",
    "        return items\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self):\n",
    "        snippets_str = \"\\n  \".join(str(snippet)\n",
    "                                   for snippet in self.scoredCodeSnippets)\n",
    "        return (f\"SearchItem(searchItemId='{self.searchItemId}', \"\n",
    "                f\"scoredCodeSnippets=[\\n  {snippets_str}\\n])\")\n",
    "\n",
    "\n",
    "def flatten_search_items(search_results: List[SearchItem]):\n",
    "    items = []\n",
    "    for result in search_results:\n",
    "        for item in result.get_flattened():\n",
    "            items.append(item)\n",
    "    return items\n",
    "\n",
    "def json_to_classes(json_data):\n",
    "    search_items = []\n",
    "    for item in json_data:\n",
    "        searchItemId = item[\"searchItemId\"]\n",
    "        scoredCodeSnippets = []\n",
    "        for snippet in item[\"scoredCodeSnippets\"]:\n",
    "            cluster = -1\n",
    "            if \"clusterIndex\" in snippet:\n",
    "                cluster = int(snippet[\"clusterIndex\"])\n",
    "            scoredCodeSnippets.append(\n",
    "                ScoredCodeSnippet(\n",
    "                    id=snippet[\"id\"],\n",
    "                    body=snippet[\"body\"],\n",
    "                    header=snippet[\"header\"],\n",
    "                    score=float(snippet[\"score\"]),\n",
    "                    cluster=cluster\n",
    "                )\n",
    "            )\n",
    "        search_items.append(SearchItem(searchItemId, scoredCodeSnippets))\n",
    "    return search_items\n",
    "\n",
    "\n",
    "def read_rag(file_name):\n",
    "    result = None\n",
    "    with open(f\"../code/RAG/{file_name}.json\", \"r\") as file:\n",
    "        data = json.load(file)\n",
    "        result = json_to_classes(data)\n",
    "\n",
    "    return result\n",
    "\n",
    "def read_naive_code2code_ext_rag():\n",
    "    return read_rag(\"results_full_code2code_ext\")\n",
    "\n",
    "def read_naive_code2code_rag():\n",
    "    return read_rag(\"results_full_code2code\")\n",
    "\n",
    "def read_naive_code2code_clustered_rag():\n",
    "    return read_rag(\"results_full_code2code_clustered\")\n",
    "\n",
    "def read_random():\n",
    "    return read_rag(\"results_random\")\n",
    "\n",
    "def read_random_fair():\n",
    "    return read_rag(\"results_random_fair\")\n",
    "\n",
    "def read_naive_full_header_rag():\n",
    "    return read_rag(\"results_full_header\")\n",
    "\n",
    "\n",
    "def read_naive_full_bigvul_header_rag():\n",
    "    return read_rag(\"results_full_header_bigvul\")\n",
    "\n",
    "def read_naive_full_func_rag():\n",
    "    return read_rag(\"results_full_func\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "5KMucbGwQ9DT"
   },
   "outputs": [],
   "source": [
    "# import openai\n",
    "import re\n",
    "import concurrent.futures\n",
    "import threading\n",
    "import time\n",
    "# from rag import SearchItem, ScoredCodeSnippet\n",
    "from typing import List, Callable\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"  # Explicitly select GPU 0\n",
    "CODEQWEN_ARCHITECTURE = \"Qwen/Qwen2.5-Coder-1.5B\"\n",
    "# CODEQWEN_ARCHITECTURE = \"Qwen/CodeQwen1.5-7B\"\n",
    "place_holders = {1: \"$MY_UNIQUE_PLACE_HOLDER_1\", 2: \"$MY_UNIQUE_PLACE_HOLDER_2\",\n",
    "                 3: \"$MY_UNIQUE_PLACE_HOLDER_3\", 4: \"$MY_UNIQUE_PLACE_HOLDER_4\", 5: \"$MY_UNIQUE_PLACE_HOLDER_5\"}\n",
    "\n",
    "templates = {\"base\": \"\"\"\n",
    "Here are two code snippets specified below, modify code snippet No.2 in a way that it includes the logic of code No.1:\n",
    "Code Snippet 1: \"$MY_UNIQUE_PLACE_HOLDER_1\"\n",
    "\n",
    "Code Snippet 2: \"$MY_UNIQUE_PLACE_HOLDER_2\"\n",
    "\n",
    "Put the generated code inside ```C ```\n",
    "\"\"\",\n",
    "             \"extra\": \"\"\"\n",
    "Here are two code snippets specified below, modify code snippet No.2 in a way that it includes the logic of code No.1:\n",
    "Code Snippet 1: \"$MY_UNIQUE_PLACE_HOLDER_1\"\n",
    "\n",
    "Code Snippet 2: \"$MY_UNIQUE_PLACE_HOLDER_2\"\n",
    "\n",
    "Note that the following lines from the first code snippet have a high priority to be in the final modified code:\n",
    "\n",
    "Lines separated by /~/ : \"$MY_UNIQUE_PLACE_HOLDER_3\"\n",
    "\n",
    "Put the generated code inside ```C ```. (Do not include comments)\n",
    "\"\"\", \"with_example_vardef\": \"\"\"Here are three code snippets (each containing a function) specified below, look how code snippet AA is changed into BB, introduce these changes to code snippet CC.\n",
    "\n",
    "Code Snippet AA: \"$MY_UNIQUE_PLACE_HOLDER_1\"\n",
    "\n",
    "Code Snippet BB: \"$MY_UNIQUE_PLACE_HOLDER_2\"\n",
    "\n",
    "Code Snippet CC: \"$MY_UNIQUE_PLACE_HOLDER_3\"\n",
    "\n",
    "Note that the following lines from code snippet CC have a high priority to be in the final modified code:\n",
    "\n",
    "Lines separated by /~/ : \"$MY_UNIQUE_PLACE_HOLDER_4\"\n",
    "\n",
    "Put the generated code inside ```C ```”, and note that the output should be single function with a similar name and parameters as the code snippet CC, and the return statements should be placed after the logic of the code. $MY_UNIQUE_PLACE_HOLDER_5\n",
    "\"\"\",\n",
    "\"vardef\": \"(Don't Forget to add these variables to function's input arguments: $MY_UNIQUE_PLACE_HOLDER_1)\",\n",
    "\n",
    "\"without_example_vardef\": \"\"\"Here are two code snippets specified below, modify code snippet BB in a way that it includes the logic of code AA:\n",
    "\n",
    "Code Snippet AA: \"$MY_UNIQUE_PLACE_HOLDER_1\"\n",
    "\n",
    "Code Snippet BB: \"$MY_UNIQUE_PLACE_HOLDER_2\"\n",
    "\n",
    "Note that the following lines from the code snippet AA have a high priority to be in the final modified code:\n",
    "\n",
    "Lines separated by /~/ : \"$MY_UNIQUE_PLACE_HOLDER_3\"\n",
    "\n",
    "Put the generated code inside ```C ``` and note that the output should be single function with a similar function definition as code snippet BB, and the return statements should be placed after the logic of the code. $MY_UNIQUE_PLACE_HOLDER_4\"\"\",\n",
    "\"ext\":\"\"\"Here's two code snippets AA and BB, each including a function. Add some parts of the logic of AA to BB in a way that the result would include all of BB but is not equal to BB. You can add variables to BB to produce a more correct code.\n",
    "\n",
    "Code Snippet AA: \"$MY_UNIQUE_PLACE_HOLDER_1\"\n",
    "\n",
    "Code Snippet BB: \"$MY_UNIQUE_PLACE_HOLDER_2\"\n",
    "\n",
    "Put the generated code inside ```C ``` and note that the final result should a function that takes all the input args of BB and more if required. (Do not include comments)\n",
    "\"\"\", \"ext_wl\":\n",
    "\"\"\"Here's two code snippets AA and BB, each including a function. Add some parts of the logic of AA to BB in a way that the result would include important lines of BB with some parts from AA. You can add variables to BB to produce a more correct code.\n",
    "\n",
    "Code Snippet AA: \"$MY_UNIQUE_PLACE_HOLDER_1\"\n",
    "\n",
    "Code Snippet BB: \"$MY_UNIQUE_PLACE_HOLDER_2\"\n",
    "\n",
    "The following lines from BB are important and should be included in the final result, the rest may be changed or even removed if they have no relation to these lines: (Lines are separated via /~/)\n",
    "\n",
    "\"$MY_UNIQUE_PLACE_HOLDER_3\"\n",
    "\n",
    "Put the generated code inside ```C ``` and note that the final result should a function that takes all the input args of BB and more if required. (Do not include comments)\n",
    "\"\"\", \"mutation_naive\": \"\"\"Here's a code snippets including a function. Except for the important lines mentioned below and the function's name and input variables, mutate the rest of the code so it is different from the original while keeping the original semantics.\n",
    "\n",
    "Code Snippet: \"$MY_UNIQUE_PLACE_HOLDER_1\"\n",
    "\n",
    "The following lines are important and should be included in the final result, the rest may be changed or even removed if they have no relation to these lines: (Lines are separated via /~/)\n",
    "\n",
    "\"$MY_UNIQUE_PLACE_HOLDER_2\"\n",
    "\n",
    "Put the generated code inside ```C ```. (Do not include comments)\n",
    "\"\"\", \"mutation\": \"\"\"Here's a code snippet including a function. Except for the important lines mentioned below, mutate the rest of the code snippet so it is different from the original while keeping the original semantics.\n",
    "To do so you can use one or more of the following rules:\n",
    "\n",
    "Rules: 1-> Replace the local variables’ identifiers with new non-repeated identifiers\n",
    "2-> Replace the for statement with an semantic-equivalent while statement, and vice versa\n",
    "3-> Change the assignment x++ into x=x+1 or x=x+1 into x+=1\n",
    "4-> Merge the declaration statements into a single composite declaration statement\n",
    "5-> Divide the composite declaration statement into separated declaration statements\n",
    "6-> Switch the two code blocks in the if statement and the corresponding else statement\n",
    "7-> Change a single if statement into a conditional expression statement.\n",
    "8-> Change a conditional expression statement into a single if statement\n",
    "9-> Divide a infix expression into two expressions whose values are stored in temporary variables\n",
    "10-> Divide a if statement with a compound condition (∧ , ∨, or ¬) into two nested if statements\n",
    "11-> Switch the places of two adjacent statements in a code block, where the former statement has no shared variable with the latter statement\n",
    "12-> Replace the if-continue statement in a loop block with if-else statement\n",
    "13-> Switch the two expressions on both sides of the infix expression whose operator is =\n",
    "14-> Switch the two string objects on both sides of an equality expression\n",
    "15-> Divide a pre-fix or post-fix expression into two expressions whose values are stored in temporary variables\n",
    "16-> Transform the ‘‘Switch-Case’’ statement into the corresponding ‘‘If-Else’’ statement.\n",
    "\n",
    "Code Snippet: \"$MY_UNIQUE_PLACE_HOLDER_1\"\n",
    "\n",
    "The following lines are important and should be included in the final result, but they can still be changed using only the first 5 rules, the rest may be changed using any of the rules or can even be removed if they have no relation to these lines: (Lines are separated via /~/)\n",
    "\n",
    "\"$MY_UNIQUE_PLACE_HOLDER_2\"\n",
    "\n",
    "Put the generated code inside ```C ```. (Do not include comments)\n",
    "\"\"\"  # 2 of the rules were merged for simplicity\n",
    "}\n",
    "\n",
    "class CodeQwenPrompter:\n",
    "    def __init__(self, system_message=\"You are a helpful assistant.\", lock=None) -> None:\n",
    "        self.messages = None\n",
    "        self.system_message = system_message\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(CODEQWEN_ARCHITECTURE)\n",
    "        self.lock = lock\n",
    "        self.prompt = self._prompt\n",
    "        if lock != None:\n",
    "            self.selector = 0\n",
    "            self.prompt=self._multi_model_prompt\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(CODEQWEN_ARCHITECTURE, torch_dtype=\"auto\", device_map=\"cuda:0\"  # Forces only GPU 0\n",
    "                                                              , max_memory={0: \"8GB\", 1: \"8GB\", 2: \"8GB\", 3: \"8GB\"},cache_dir=\"./model_cache/\")\n",
    "            self.model2 = AutoModelForCausalLM.from_pretrained(CODEQWEN_ARCHITECTURE, torch_dtype=\"auto\", device_map=\"cuda:0\"  # Forces only GPU 0\n",
    "                                                               , max_memory={0: \"8GB\", 1: \"8GB\", 2: \"8GB\", 3:\"8GB\"} ,cache_dir=\"./model_cache/\")\n",
    "            # self.model3 = AutoModelForCausalLM.from_pretrained(CODEQWEN_ARCHITECTURE, torch_dtype=\"auto\", device_map=\"balanced\", max_memory={0: \"8GB\", 1: \"8GB\", 2: \"8GB\", 3: \"8GB\"} ,cache_dir=\"./model_cache/\")\n",
    "            # self.model4 = AutoModelForCausalLM.from_pretrained(CODEQWEN_ARCHITECTURE, torch_dtype=\"auto\", device_map=\"balanced\", max_memory={0: \"8GB\", 1: \"8GB\", 2: \"8GB\", 3: \"8GB\"} ,cache_dir=\"./model_cache/\")\n",
    "            # self.models = {0:self.model, 1:self.model2, 2: self.model3, 3:self.model4}\n",
    "            self.models = {0:self.model, 1:self.model2}\n",
    "\n",
    "        else:\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(CODEQWEN_ARCHITECTURE, torch_dtype=\"auto\", device_map=\"cuda:0\", cache_dir=\"./model_cache/\" , max_memory={0: \"15GB\", 1: \"15GB\"})\n",
    "\n",
    "    def _multi_model_prompt(self, message, clean=True, show=False):\n",
    "        model = None\n",
    "        print(self.selector)\n",
    "        with self.lock:\n",
    "            model = self.models[self.selector % len(self.models)]\n",
    "            self.selector += 1\n",
    "\n",
    "                # print(t)\n",
    "        if self.messages == None or clean:\n",
    "            self.messages = [\n",
    "                # system message to set the behavior of the assistant\n",
    "                {\"role\": \"system\", \"content\": self.system_message},\n",
    "            ]\n",
    "\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "        text = self.tokenizer.apply_chat_template(\n",
    "            self.messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "\n",
    "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "        print(self.tokenizer.decode(text[0]))\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            model_inputs.input_ids,\n",
    "            max_new_tokens=4096 # ChatGPT defaults to 4096\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "\n",
    "        reply = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "        if show:\n",
    "            print(reply)\n",
    "\n",
    "        return reply\n",
    "\n",
    "\n",
    "    # clean initially, it is always dirty after use\n",
    "    def _prompt(self, message, clean=True, show=False):\n",
    "        # print(t)\n",
    "        if self.messages == None or clean:\n",
    "            self.messages = [\n",
    "                # system message to set the behavior of the assistant\n",
    "                {\"role\": \"system\", \"content\": self.system_message},\n",
    "            ]\n",
    "\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "        text = self.tokenizer.apply_chat_template(\n",
    "            self.messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # Ensure pad_token_id is set correctly\n",
    "        # if self.tokenizer.pad_token_id is None:\n",
    "        #     self.tokenizer.pad_token = self.tokenizer.eos_token  # Set pad token to eos token\n",
    "\n",
    "        generated_ids = self.model.generate(\n",
    "            input_ids=model_inputs.input_ids,\n",
    "            attention_mask=model_inputs.attention_mask,\n",
    "            pad_token_id=self.tokenizer.pad_token_id,\n",
    "            max_new_tokens=1024, # ChatGPT defaults to 4096\n",
    "            do_sample=True,\n",
    "            num_beams=4\n",
    "        )\n",
    "        # generated_ids = [\n",
    "        #     output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        # ]\n",
    "\n",
    "        reply = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "        if show:\n",
    "            print(reply)\n",
    "\n",
    "        return reply\n",
    "\n",
    "class PromptUtils:\n",
    "    @staticmethod\n",
    "    def extract_code_content(text):\n",
    "        print(text)\n",
    "        start_index = text.find('```C') + 4\n",
    "        print('start_index')\n",
    "        print(start_index)\n",
    "        end_index = text.find('```', start_index)\n",
    "        print('end_index')\n",
    "        print(end_index)\n",
    "        if start_index != -1 and end_index != -1:\n",
    "            print(text[start_index:end_index].strip())\n",
    "            return text[start_index:end_index].strip()\n",
    "        else:\n",
    "            print(\"Sth is wrong!\")\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_vardef(vul, vulnerable_lines):\n",
    "        # Step 1: Extract the arguments string from the function definition\n",
    "        # Using re.DOTALL to allow the dot to match newlines\n",
    "        args_match = re.search(r'\\((.*?)\\)', vul, re.DOTALL)\n",
    "        if args_match:\n",
    "            args_str = args_match.group(1)\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "        # Step 2: Split the arguments string into individual arguments\n",
    "        # This uses a regular expression to split on commas not inside parentheses\n",
    "        full_args = [arg.strip()\n",
    "                     for arg in re.split(r',\\s*(?![^()]*\\))', args_str)]\n",
    "\n",
    "        # Step 3: Extract argument names, ignoring types\n",
    "        args = []\n",
    "        for arg in full_args:\n",
    "            # Handle cases with pointers and references\n",
    "            arg_name = arg.split()[-1].replace('*', '').replace('&', '')\n",
    "            args.append(arg_name)\n",
    "\n",
    "        # Step 4: Check which arguments are used in vulnerable_lines\n",
    "        used_args = []\n",
    "        used_full_args = []\n",
    "        for i, arg in enumerate(args):\n",
    "            if re.search(r'\\b' + re.escape(arg) + r'\\b', vulnerable_lines):\n",
    "                used_args.append(arg)\n",
    "                used_full_args.append(full_args[i])\n",
    "\n",
    "        # Step 5: Format and print the results\n",
    "        return f\"(Don't Forget to add these variables to function's input arguments: {', '.join(full_arg for arg, full_arg in zip(used_args, used_full_args))})\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_full_prompt_without_examples_and_vardef_guide(vul, clean, vulnerable_lines):\n",
    "        vardef = PromptUtils.get_vardef(vul, vulnerable_lines)\n",
    "        return templates[\"without_example_vardef\"].replace(place_holders[1], vul).replace(place_holders[2], clean).replace(place_holders[3], vulnerable_lines).replace(place_holders[4], vardef)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_full_prompt_with_examples_and_vardef_guide(fixed, vul, clean, vulnerable_lines):\n",
    "        vardef = PromptUtils.get_vardef(vul, vulnerable_lines)\n",
    "        return templates[\"with_example_vardef\"].replace(place_holders[1], fixed).replace(place_holders[2], vul).replace(place_holders[3], clean).replace(place_holders[4], vulnerable_lines).replace(place_holders[5], vardef)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_full_prompt(snippet1, snippet2, vulnerable_lines):\n",
    "        return templates[\"extra\"].replace(place_holders[1], snippet1).replace(place_holders[2], snippet2).replace(place_holders[3], vulnerable_lines)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_ext_wl_prompt(clean, vul, vulnerable_lines):\n",
    "        return templates[\"ext_wl\"].replace(place_holders[1], clean).replace(place_holders[2], vul).replace(place_holders[3], vulnerable_lines)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_mutation_prompt(vul, vulnerable_lines):\n",
    "        return templates[\"mutation\"].replace(place_holders[1], vul).replace(place_holders[2], vulnerable_lines)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_ext_prompt(clean, vul):\n",
    "        return templates[\"ext\"].replace(place_holders[1], clean).replace(place_holders[2], vul)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_prompt(snippet1, snippet2):\n",
    "        return templates[\"base\"].replace(place_holders[1], snippet1).replace(place_holders[2], snippet2)\n",
    "\n",
    "\n",
    "class ConcurrencyUtils:\n",
    "\n",
    "    @staticmethod\n",
    "    def wait_for_all_futures(futures):\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"something's up {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def concurrent_chatgpt_call(prompt_creator_from_searchItem: Callable[[SearchItem], str],\n",
    "                                index_retreiver: Callable[[SearchItem], str],\n",
    "                                vul_retriever: Callable[[SearchItem], str],\n",
    "                                clean_retriever: Callable[[SearchItem], str],\n",
    "                                vul_lines_retriever: Callable[[SearchItem], str],\n",
    "                                search_item: SearchItem,\n",
    "                                indices: List, vuls: List, cleans: List, vul_lines: List, generated: List,\n",
    "                                lock, llm, retry=2) -> None:\n",
    "        if retry <= 0:\n",
    "            return\n",
    "\n",
    "\n",
    "        try:\n",
    "            prompt = prompt_creator_from_searchItem(search_item)\n",
    "            # print('prompt')\n",
    "            # print(prompt)\n",
    "            code = PromptUtils.extract_code_content(llm.prompt(prompt))\n",
    "            print('code')\n",
    "            if code == None:\n",
    "                print(f\"Empty Code response - retry at {retry}\")\n",
    "                ConcurrencyUtils.concurrent_chatgpt_call(prompt_creator_from_searchItem,\n",
    "                                                     index_retreiver,\n",
    "                                                     vul_retriever,\n",
    "                                                     clean_retriever,\n",
    "                                                     vul_lines_retriever,\n",
    "                                                     search_item,\n",
    "                                                     indices, vuls, cleans, vul_lines, generated,\n",
    "                                                     lock, llm, retry=retry - 1)\n",
    "\n",
    "            with lock:\n",
    "                generated.append(code)\n",
    "                indices.append(index_retreiver(search_item))\n",
    "                vuls.append(vul_retriever(search_item))\n",
    "                cleans.append(clean_retriever(search_item))\n",
    "                vul_lines.append(vul_lines_retriever(search_item))\n",
    "\n",
    "            print(\"Success!\")\n",
    "\n",
    "        # except (openai.error.APIError, torch.cuda.OutOfMemoryError) as e:\n",
    "        #     print(f\"ex happend {e}\")\n",
    "        #     # print(f\"Arguments: {e.args}\")\n",
    "        #     print(f\"Exception class: {e.__class__}\")\n",
    "        #     print(f\"Cause: {e.__cause__}\")\n",
    "        #     print(f\"Context: {e.__context__}\")\n",
    "        #     print(f\"API Error - retry at {retry}\")\n",
    "        #     time.sleep(retry + 1) # maybe the server wasn't available so wait\n",
    "        #     ConcurrencyUtils.concurrent_chatgpt_call(prompt_creator_from_searchItem,\n",
    "        #                                              index_retreiver,\n",
    "        #                                              vul_retriever,\n",
    "        #                                              clean_retriever,\n",
    "        #                                              vul_lines_retriever,\n",
    "        #                                              search_item,\n",
    "        #                                              indices, vuls, cleans, vul_lines, generated,\n",
    "        #                                              lock, llm, retry=retry - 1)\n",
    "        except Exception as e:\n",
    "            print(f\"ex happend {e}\")\n",
    "            print(f\"Arguments: {e.args}\")\n",
    "            print(f\"Exception class: {e.__class__}\")\n",
    "            print(f\"Cause: {e.__cause__}\")\n",
    "            print(f\"Context: {e.__context__}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def concurrent_prompter(prompt_creator_from_searchItem: Callable[[SearchItem], str],\n",
    "                            index_retreiver: Callable[[SearchItem], str],\n",
    "                            vul_retriever: Callable[[SearchItem], str],\n",
    "                            clean_retriever: Callable[[SearchItem], str],\n",
    "                            vul_lines_retriever: Callable[[SearchItem], str],\n",
    "                            search_results: List[SearchItem], llm,\n",
    "                            target: int = 2000, max_workers=60, is_all=False, resume_from_dataframe=None):\n",
    "        vuls = []\n",
    "        cleans = []\n",
    "        vul_lines = []\n",
    "        indices = []\n",
    "        generated = []\n",
    "        starting_index = 0\n",
    "\n",
    "        if resume_from_dataframe is not None:\n",
    "            print(\"resuming from dataframe\")\n",
    "            for index, row in resume_from_dataframe.iterrows():\n",
    "                generated.append(str(row['generated']))\n",
    "                indices.append(str(row['idx']))\n",
    "                vuls.append(str(row[\"vul\"]))\n",
    "                vul_lines.append(str(row[\"vul_lines\"]))\n",
    "                cleans.append(str(row[\"clean\"]))\n",
    "\n",
    "            max_indx = -1\n",
    "            for idx in indices:\n",
    "                list_indx = next((j for j, result in enumerate(search_results) if result.best == idx), None)\n",
    "                if list_indx != None and list_indx > max_indx:\n",
    "                    max_indx = list_indx\n",
    "\n",
    "            starting_index = max_indx + 1\n",
    "        print(f\"starting with index: {starting_index}\")\n",
    "\n",
    "        lock = threading.Lock()\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executors:\n",
    "            futures = [executors.submit(\n",
    "                ConcurrencyUtils.concurrent_chatgpt_call,\n",
    "                prompt_creator_from_searchItem,\n",
    "                index_retreiver, vul_retriever,\n",
    "                clean_retriever, vul_lines_retriever,\n",
    "                search_results[i], indices, vuls, cleans,\n",
    "                vul_lines, generated, lock, llm) for i in range(starting_index,target)]\n",
    "\n",
    "            ConcurrencyUtils.wait_for_all_futures(futures)\n",
    "            end = target\n",
    "\n",
    "            while len(generated) < target:\n",
    "\n",
    "                if is_all:\n",
    "                    break\n",
    "\n",
    "                remaining = target - len(generated)\n",
    "                new_limit = end + remaining\n",
    "\n",
    "                print(f\"DEBUG: Done is: {len(generated)}\")\n",
    "                print(f\"DEBUG: Last i: {new_limit}\")\n",
    "                futures = [executors.submit(ConcurrencyUtils.concurrent_chatgpt_call,\n",
    "                                            prompt_creator_from_searchItem,\n",
    "                                            index_retreiver, vul_retriever,\n",
    "                                            clean_retriever, vul_lines_retriever,\n",
    "                                            search_results[i], indices, vuls, cleans,\n",
    "                                            vul_lines, generated, lock, llm)\n",
    "                           for i in range(end, new_limit)]\n",
    "                ConcurrencyUtils.wait_for_all_futures(futures)\n",
    "                end = new_limit\n",
    "\n",
    "        return indices, vuls, cleans, vul_lines, generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388,
     "referenced_widgets": [
      "eb8050759f214d9abf3a953d40772bda",
      "e5c6d4842ad54793a259c2cdd53403fa",
      "e8e1ea806614495182385b939174c8e3",
      "f244532039244f0ca83d0ac32c52bdda",
      "ba5913acc1df49b48a670924be88e58e",
      "61bc6ea7c468421690dd0bc59c96f05d",
      "19fcc10394cf4802a1588998c0452c90",
      "03b6ccb57b9040aab108fcdbc4527111",
      "7c946a3769cf4b91b65760a7d8822fb1",
      "2e11cd13e59d4e1883abfaab31060d54",
      "005d0341ea6641f6a4791478ed314311",
      "2b26301a4aeb4b15b325f2bf5c9bd09f",
      "8eafb62d497c4d7aaf5c633474d02da0",
      "f18b5e7509d74e86956a3bc266289132",
      "63d7d35d333742c5992beea2d1c273c8",
      "4f8244c8ba5a4184a4c7096ffdde7250",
      "5dcf1330e1074ff08c3e866b8e68eb07",
      "07b53d4510e14e27aadf6f243da18aaf",
      "70ddb3252c5944f89ecf242c3b0d63f9",
      "fed0215cd5fb4aa795fa4eb4c6e882fa",
      "278a282d37d6434f90c7fd6680c06b09",
      "f877f96eb82d40039b02bd51ea308c17",
      "36e2b042b4bc4b4b9c9a77eb9c5b3b44",
      "d1e55069f9e545749f3971d944bccfd6",
      "dfa350f887994bc48b66119fc6486881",
      "828f75b3426d4ff189509cd0a842e438",
      "cb36422a241147c99777a6a99ae8c3d9",
      "306dceeea0784de4b7e88f4cde9cf521",
      "385697c4bd3f428885c6bbd8d03ccbf3",
      "3adb51dbab0b4ca38e069f7b9c8c2a5b",
      "fd58db648108455aaec268f590906007",
      "8d9f28ac464a4c6395ee7192b519d040",
      "1e9438d9af8e4f739641151ab3653ebb",
      "63a36ff6ae1544219da744271760dea1",
      "2fff5bc8fa634856b9f14952e558ffcd",
      "2d1f33fbdfc04b4f87dfdb30bca3225c",
      "639acc24a01f49be8fabf0c76148bd30",
      "62fd80d356054bd09e609e37b0975340",
      "768e58e484c042a0944b5ac19e83665b",
      "557a9427351b45ba9545ce332d40b665",
      "b7f7febeb4ae414faa698e665adbc32f",
      "f39d2c669f9d41e8af6de6ab050879a2",
      "f3efa7c6655140a7b342b99a88c1c05c",
      "778d34104a954257b9a713e7f4f696ce",
      "5f886e342b814f478e7e0da656a49bc7",
      "aa0284c9ccd64058926653c2d1ae50f9",
      "6bcee50339cf42acbadc051a682ec1c8",
      "c9cc357c3642493d832e0987086343e4",
      "dc99fe811abf475d80cd622f90b9b6c5",
      "4b038a9843654347bd300e1945408ebe",
      "661a72e797354a1192cef9fac7638151",
      "26a5990dd12d4c069dfc4153073d00c7",
      "697593ee9ee74e779d489fe0d21c31e9",
      "dfd11c763f8a4f68bc9379815bd5c38c",
      "6890f2aa23334e55b681d3b1d57e878d",
      "95bbcaddee5b46f6a8a4a003dbb4de48",
      "eed2180e1e18432da769369fb0d5cd9f",
      "fbc4ffed7274465ba6e9955f881e03e6",
      "3ecd955e6d74438ba39e8ab3ce6e5520",
      "ae843c1e0d5a4d41af67f9ad20886b3e",
      "df5a6e83d60843969d8cca9c4f669ee3",
      "2740b36a48a942c79c00d396b393a188",
      "5bfd08271f984f06899939df9f7c478a",
      "e8f10149ed324d89a883b6876c012d2e",
      "968cd6fbea5244189f7b971143994f35",
      "fe62d8520c0f44369928277280c2606a",
      "2a3c6a7d26c54985b53fba9bd4ce3a21",
      "3cb027ce1734479db2a68e1c05d8622c",
      "3f2c38f76ede4ab6b2fd41028fa88323",
      "5453f349917242248efdbb33c6ce986f",
      "ea000cf25e234dc18e6c6adf800ff626",
      "edce3e0fcde443d48ff517db3028c803",
      "984f83669ba14f1d9c07a3036eecc847",
      "4d3456166f3e4242b15e8f547410ee35",
      "af680cda0b5b48a4adfc916f13dd8e9c",
      "0ec313b39f2542909da5117f9c5eb230",
      "b7267a5741064dbeba307399be30f02b"
     ]
    },
    "executionInfo": {
     "elapsed": 46713,
     "status": "ok",
     "timestamp": 1743578328805,
     "user": {
      "displayName": "Thien Ngan",
      "userId": "09935523481613786802"
     },
     "user_tz": -420
    },
    "id": "czrAlgpbPkTt",
    "outputId": "349e85b2-6e7b-4e78-c3f5-102812cced29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from chat import PromptUtils\n",
    "\n",
    "extract_code_content = PromptUtils.extract_code_content\n",
    "\n",
    "# from chat import CodeQwenPrompter as code_qwen\n",
    "# from chat import PromptUtils as pu\n",
    "\n",
    "ch = CodeQwenPrompter(lock=None) # Selects CodeQwen1.5--7B-Chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'system\\nYou are a helpful assistant.\\nuser\\n\\' \\nHere are two code snippets specified below, modify code snippet No.2 in a way that it includes the logic of code No.1:\\nCode Snippet 1: \"static int\\nProcPseudoramiXGetScreenSize(ClientPtr client)\\n{\\n    REQUEST(xPanoramiXGetScreenSizeReq);\\n    WindowPtr pWin;\\n    xPanoramiXGetScreenSizeReply rep;\\n    register int rc;\\n\\n    TRACE;\\n\\n    if (stuff->screen >= pseudoramiXNumScreens)\\n      return BadMatch;\\n\\n    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);\\n    rc = dixLookupWindow(&pWin, stuff->window, client, DixGetAttrAccess);\\n    if (rc != Success)\\n        return rc;\\n\\n    rep.type = X_Reply;\\n    rep.length = 0;\\n    rep.sequenceNumber = client->sequence;\\n    /* screen dimensions */\\n    rep.width = pseudoramiXScreens[stuff->screen].w;\\n    // was screenInfo.screens[stuff->screen]->width;\\n    rep.height = pseudoramiXScreens[stuff->screen].h;\\n    // was screenInfo.screens[stuff->screen]->height;\\n    rep.window = stuff->window;\\n    rep.screen = stuff->screen;\\n    if (client->swapped) {\\n        swaps(&rep.sequenceNumber);\\n        swapl(&rep.length);\\n        swapl(&rep.width);\\n        swapl(&rep.height);\\n        swapl(&rep.window);\\n        swapl(&rep.screen);\\n    }\\n    WriteToClient(client, sizeof(xPanoramiXGetScreenSizeReply),&rep);\\n    return Success;\\n}\"\\n\\nCode Snippet 2: \"static int\\nSProcPseudoramiXIsActive(ClientPtr client)\\n{\\n    REQUEST(xXineramaIsActiveReq);\\n\\n    TRACE;\\n\\n    swaps(&stuff->length);\\n    REQUEST_SIZE_MATCH(xXineramaIsActiveReq);\\n    return ProcPseudoramiXIsActive(client);\\n}\"\\n\\nNote that the following lines from the first code snippet have a high priority to be in the final modified code:\\n\\nLines separated by /~/ : \"{\\'deleted_lines\\': [\\'    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);\\'], \\'added_lines\\': [\\'    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);\\', \\'\\']}\"\\n\\nPut the generated code inside ```C ```. (Do not include comments)\\n\\n\\n\\nassistant\\n\\' \\nHere are two code snippets specified below, modify code snippet No.2 in a way that it includes the logic of code No.1:\\nCode Snippet 1: \"static int\\nProcPseudoramiXGetScreenSize(ClientPtr client)\\n{\\n    REQUEST(xPanoramiXGetScreenSizeReq);\\n    WindowPtr pWin;\\n    xPanoramiXGetScreenSizeReply rep;\\n    register int rc;\\n\\n    TRACE;\\n\\n    if (stuff->screen >= pseudoramiXNumScreens)\\n      return BadMatch;\\n\\n    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);\\n    rc = dixLookupWindow(&pWin, stuff->window, client, DixGetAttrAccess);\\n    if (rc != Success)\\n        return rc;\\n\\n    rep.type = X_Reply;\\n    rep.length = 0;\\n    rep.sequenceNumber = client->sequence;\\n    /* screen dimensions */\\n    rep.width = pseudoramiXScreens[stuff->screen].w;\\n    // was screenInfo.screens[stuff->screen]->width;\\n    rep.height = pseudoramiXScreens[stuff->screen].h;\\n    // was screenInfo.screens[stuff->screen]->height;\\n    rep.window = stuff->window;\\n    rep.screen = stuff->screen;\\n    if (client->swapped) {\\n        swaps(&rep.sequenceNumber);\\n        swapl(&rep.length);\\n        swapl(&rep.width);\\n        swapl(&rep.height);\\n        swapl(&rep.window);\\n        swapl(&rep.screen);\\n    }\\n    WriteToClient(client, sizeof(xPanoramiXGetScreenSizeReply),&rep);\\n    return Success;\\n}\"\\n\\nCode Snippet 2: \"static int\\nSProcPseudoramiXIsActive(ClientPtr client)\\n{\\n    REQUEST(xXineramaIsActiveReq);\\n\\n    TRACE;\\n\\n    swaps(&stuff->length);\\n    REQUEST_SIZE_MATCH(xXineramaIsActiveReq);\\n    return ProcPseudoramiXIsActive(client);\\n}\"\\n\\nNote that the following lines from the first code snippet have a high priority to be in the final modified code:\\n\\nLines separated by /~/ : \"{\\'deleted_lines\\': [\\'    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);\\'], \\'added_lines\\': [\\'    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);\\', \\'\\']}\"\\n\\nPut the generated code inside ```C ```. (Do not include comments)\\n\\n```C\\nstatic int\\nProcPseudoramiXGetScreenSize(ClientPtr client)\\n{\\n    REQUEST(xPanoramiXGetScreenSizeReq);\\n    WindowPtr pWin;\\n    xPanoramiXGetScreenSizeReply rep;\\n    register int rc;\\n\\n    TRACE;\\n\\n    if (stuff->screen >= pseudoramiXNumScreens)\\n      return BadMatch;\\n\\n    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);\\n    rc = dixLookupWindow(&pWin, stuff->window, client, DixGetAttrAccess);\\n    if (rc != Success)\\n        return rc;\\n\\n    rep.type = X_Reply;\\n    rep.length = 0;\\n    rep.sequenceNumber = client->sequence;\\n    /* screen dimensions */\\n    rep.width = pseudoramiXScreens[stuff->screen].w;\\n    // was screenInfo.screens[stuff->screen]->width;\\n    rep.height = pseudoramiXScreens[stuff->screen].h;\\n    // was screenInfo.screens[stuff->screen]->height;\\n    rep.window = stuff->window;\\n    rep.screen = stuff->screen;\\n    if (client->swapped) {\\n        swaps(&rep.sequenceNumber);\\n        swapl(&rep.length);\\n        swapl(&rep.width);\\n        swapl(&rep.height);\\n        swapl(&rep.window);\\n        swapl(&rep.screen);\\n    }\\n    WriteToClient(client, sizeof(xPanoramiXGetScreenSizeReply),&rep);\\n    return Success;\\n}\\n\\nstatic int\\nSProcPseudoramiXIsActive(ClientPtr client)\\n{\\n    REQUEST(xXineramaIsActiveReq);\\n\\n    TRACE;\\n\\n    swaps(&stuff->length);\\n    REQUEST_SIZE_MATCH(xXineramaIsActiveReq);\\n    return ProcPseudoramiXIsActive(client);\\n}\\n```'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = '''' \n",
    "Here are two code snippets specified below, modify code snippet No.2 in a way that it includes the logic of code No.1:\n",
    "Code Snippet 1: \"static int\n",
    "ProcPseudoramiXGetScreenSize(ClientPtr client)\n",
    "{\n",
    "    REQUEST(xPanoramiXGetScreenSizeReq);\n",
    "    WindowPtr pWin;\n",
    "    xPanoramiXGetScreenSizeReply rep;\n",
    "    register int rc;\n",
    "\n",
    "    TRACE;\n",
    "\n",
    "    if (stuff->screen >= pseudoramiXNumScreens)\n",
    "      return BadMatch;\n",
    "\n",
    "    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);\n",
    "    rc = dixLookupWindow(&pWin, stuff->window, client, DixGetAttrAccess);\n",
    "    if (rc != Success)\n",
    "        return rc;\n",
    "\n",
    "    rep.type = X_Reply;\n",
    "    rep.length = 0;\n",
    "    rep.sequenceNumber = client->sequence;\n",
    "    /* screen dimensions */\n",
    "    rep.width = pseudoramiXScreens[stuff->screen].w;\n",
    "    // was screenInfo.screens[stuff->screen]->width;\n",
    "    rep.height = pseudoramiXScreens[stuff->screen].h;\n",
    "    // was screenInfo.screens[stuff->screen]->height;\n",
    "    rep.window = stuff->window;\n",
    "    rep.screen = stuff->screen;\n",
    "    if (client->swapped) {\n",
    "        swaps(&rep.sequenceNumber);\n",
    "        swapl(&rep.length);\n",
    "        swapl(&rep.width);\n",
    "        swapl(&rep.height);\n",
    "        swapl(&rep.window);\n",
    "        swapl(&rep.screen);\n",
    "    }\n",
    "    WriteToClient(client, sizeof(xPanoramiXGetScreenSizeReply),&rep);\n",
    "    return Success;\n",
    "}\"\n",
    "\n",
    "Code Snippet 2: \"static int\n",
    "SProcPseudoramiXIsActive(ClientPtr client)\n",
    "{\n",
    "    REQUEST(xXineramaIsActiveReq);\n",
    "\n",
    "    TRACE;\n",
    "\n",
    "    swaps(&stuff->length);\n",
    "    REQUEST_SIZE_MATCH(xXineramaIsActiveReq);\n",
    "    return ProcPseudoramiXIsActive(client);\n",
    "}\"\n",
    "\n",
    "Note that the following lines from the first code snippet have a high priority to be in the final modified code:\n",
    "\n",
    "Lines separated by /~/ : \"{'deleted_lines': ['    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);'], 'added_lines': ['    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);', '']}\"\n",
    "\n",
    "Put the generated code inside ```C ```. (Do not include comments)\n",
    "\n",
    "\n",
    "'''\n",
    "ch.prompt(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedError",
     "evalue": "str object has no element 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUndefinedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_chat_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\test2\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1695\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.apply_chat_template\u001b[1;34m(self, conversation, tools, documents, chat_template, add_generation_prompt, continue_final_message, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     all_generation_indices\u001b[38;5;241m.\u001b[39mappend(generation_indices)\n\u001b[0;32m   1694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1695\u001b[0m     rendered_chat \u001b[38;5;241m=\u001b[39m compiled_template\u001b[38;5;241m.\u001b[39mrender(\n\u001b[0;32m   1696\u001b[0m         messages\u001b[38;5;241m=\u001b[39mchat,\n\u001b[0;32m   1697\u001b[0m         tools\u001b[38;5;241m=\u001b[39mtool_schemas,\n\u001b[0;32m   1698\u001b[0m         documents\u001b[38;5;241m=\u001b[39mdocuments,\n\u001b[0;32m   1699\u001b[0m         add_generation_prompt\u001b[38;5;241m=\u001b[39madd_generation_prompt,\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtemplate_kwargs,\n\u001b[0;32m   1701\u001b[0m     )\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m continue_final_message:\n\u001b[0;32m   1703\u001b[0m     final_message \u001b[38;5;241m=\u001b[39m chat[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\test2\\lib\\site-packages\\jinja2\\environment.py:1295\u001b[0m, in \u001b[0;36mTemplate.render\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mconcat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_render_func(ctx))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\test2\\lib\\site-packages\\jinja2\\environment.py:942\u001b[0m, in \u001b[0;36mEnvironment.handle_exception\u001b[1;34m(self, source)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Exception handling helper.  This is used internally to either raise\u001b[39;00m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;124;03mrewritten exceptions or return a rendered traceback for the template.\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdebug\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rewrite_traceback_stack\n\u001b[1;32m--> 942\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m rewrite_traceback_stack(source\u001b[38;5;241m=\u001b[39msource)\n",
      "File \u001b[1;32m<template>:15\u001b[0m, in \u001b[0;36mtop-level template code\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\test2\\lib\\site-packages\\jinja2\\sandbox.py:293\u001b[0m, in \u001b[0;36mSandboxedEnvironment.getitem\u001b[1;34m(self, obj, argument)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Subscribe an object from sandboxed code.\"\"\"\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[43margument\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mLookupError\u001b[39;00m):\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(argument, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[1;31mUndefinedError\u001b[0m: str object has no element 0"
     ]
    }
   ],
   "source": [
    "ch.tokenizer.apply_chat_template( '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.46.3\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: c:\\programdata\\miniconda3\\envs\\vulscriber-cluster-env\\lib\\site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cff--ocSPkTv"
   },
   "source": [
    "<!-- ## Introduciton of RAG -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "1gYhufIwPkTx",
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# from rag import read_naive_full_header_rag, read_naive_full_bigvul_header_rag, read_naive_full_func_rag, read_naive_code2code_rag, read_naive_code2code_ext_rag, read_random, read_naive_code2code_clustered_rag, read_random_fair\n",
    "\n",
    "search_results = read_naive_code2code_clustered_rag() # For Injection and Extension Methods - RQ1 and RQ3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1743578488080,
     "user": {
      "displayName": "Thien Ngan",
      "userId": "09935523481613786802"
     },
     "user_tz": -420
    },
    "id": "XtnUaK-EPkTx",
    "outputId": "0390b7ea-fe99-49fd-abcd-7c7c8572e595"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7059,\n",
       " SearchItem(searchItemId='src/C/cholmod.c', scoredCodeSnippets=[\n",
       "   ScoredCodeSnippet(id='mono/metadata/icall.c', body='static gboolean\n",
       " ves_icall_System_Array_FastCopy (MonoArray *...', header='static gboolean ves_icall_System_Array_FastCopy (MonoArray* source, int source_idx, MonoArray* dest, int dest_idx, int length)', cluster='0', score=4.092301)\n",
       "   ScoredCodeSnippet(id='codestream/acsequentialscan.hpp', body='void Init(bool hi) \n",
       "       {\n",
       "         for(int i = 0;i < 18;i++...', header='void Init(bool hi)', cluster='1', score=3.7259467)\n",
       "   ScoredCodeSnippet(id='src/C/cholmod.c', body='static PyObject* spsolve(PyObject *self, PyObject *args,\n",
       "    ...', header='static PyObject* spsolve(PyObject* self, PyObject* args, PyObject* kwrd)', cluster='2', score=18.262472)\n",
       "   ScoredCodeSnippet(id='src/imagew-bmp.c', body='static int find_high_bit(unsigned int x)\n",
       " {\n",
       " \tint i;\n",
       " \tfor(i=31...', header='static int find_high_bit(unsigned int x)', cluster='3', score=4.4920135)\n",
       "   ScoredCodeSnippet(id='libavcodec/vorbis.c', body='static void render_line(int x0, int y0, int x1, int y1, floa...', header='static void render_line(int x0, int y0, int x1, int y1, float* buf)', cluster='4', score=5.065495)\n",
       " ]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results[0].max_score, search_results[1].max_score, search_results[2].max_score, search_results[10].max_score, search_results[100].max_score\n",
    "len(search_results),search_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypkXILX0PkTx"
   },
   "source": [
    "<!-- Vì MegaVul không có trường metadata riêng cho vulnerable_lines, chúng ta sẽ giả định rằng các dòng code bị xóa (deleted_lines) trong quá trình sửa lỗi (tức là trong diff_line_info) chính là các dòng chứa hoặc liên quan trực tiếp đến lỗ hổng trong phiên bản code trước đó (func_before). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1151,
     "status": "ok",
     "timestamp": 1743578489367,
     "user": {
      "displayName": "Thien Ngan",
      "userId": "09935523481613786802"
     },
     "user_tz": -420
    },
    "id": "Jjl4-fNaPkTy",
    "metadata": {},
    "outputId": "e9b9ae2d-472a-4045-b482-cabb66315c7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7059\n",
      "35167\n"
     ]
    }
   ],
   "source": [
    "# from rag import flatten_search_items\n",
    "from operator import attrgetter\n",
    "\n",
    "def sort(search_results):\n",
    "    return sorted(search_results, key=attrgetter('max_score'), reverse=True)\n",
    "\n",
    "print(len(search_results))\n",
    "search_results = flatten_search_items(search_results) # flattens search results in case the format is (1 clean) -> 5 vuls (for RQ2) instead of 1-1 matching, otherwise it doesn't change anything\n",
    "\n",
    "search_results = sort(search_results) # sort the results (if clustering is used, this will be invalidated and the clustered sampling algorithm's sorting method will be used)\n",
    "print(len(search_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1743578493316,
     "user": {
      "displayName": "Thien Ngan",
      "userId": "09935523481613786802"
     },
     "user_tz": -420
    },
    "id": "-Opg3xsIPkTy",
    "outputId": "85ded017-9901-44cb-f47a-10b438c71515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.350285964307089 10.350285964307089 89.021286\n"
     ]
    }
   ],
   "source": [
    "\n",
    "avg = 0\n",
    "max_avg = 0\n",
    "avg_m = 0\n",
    "for r in search_results:\n",
    "    if avg_m < r.avg_score:\n",
    "        avg_m = r.avg_score\n",
    "    avg += r.avg_score / len(search_results)\n",
    "    max_avg += r.max_score/len(search_results)\n",
    "\n",
    "print(avg, max_avg, avg_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1743578494910,
     "user": {
      "displayName": "Thien Ngan",
      "userId": "09935523481613786802"
     },
     "user_tz": -420
    },
    "id": "VcVr5kP6PkTy",
    "metadata": {},
    "outputId": "e0d51e98-4ec8-48fc-b9dc-1705670cce9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusted Sampling was used...\n"
     ]
    }
   ],
   "source": [
    "def clustered_sampling(search_results):\n",
    "    if search_results[0].scoredCodeSnippets[0].cluster == -1:\n",
    "        print(\"Search results are for a non-clustered strategy, skipping clustred_sampling\")\n",
    "        return search_results\n",
    "\n",
    "    cluster_order = [4,3,1,0,2] # sorted based on size\n",
    "    cluster_indices = [0,0,0,0,0]\n",
    "\n",
    "    new_search_results = []\n",
    "\n",
    "    search_results_per_cluster = {0:[], 1:[], 2:[],3:[],4:[]}\n",
    "\n",
    "    for sr in search_results:\n",
    "        search_results_per_cluster[sr.scoredCodeSnippets[0].cluster].append(sr) # putting items of each cluster to it's array\n",
    "\n",
    "    for i in range(5):\n",
    "        search_results_per_cluster[i] = sort(search_results_per_cluster[i]) # sort each cluster's results\n",
    "\n",
    "    for i in range(len(search_results)):\n",
    "        cluster_number = cluster_order[i%5] # sampling from sorted clusters while starting from the largest cluster\n",
    "        cluster_index = cluster_indices[cluster_number]\n",
    "\n",
    "        if cluster_index < len(search_results_per_cluster[cluster_number]):\n",
    "            new_search_results.append(search_results_per_cluster[cluster_number][cluster_index])\n",
    "            cluster_indices[cluster_number] += 1\n",
    "\n",
    "    print(\"Clusted Sampling was used...\")\n",
    "    return new_search_results\n",
    "\n",
    "search_results = clustered_sampling(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1743578498807,
     "user": {
      "displayName": "Thien Ngan",
      "userId": "09935523481613786802"
     },
     "user_tz": -420
    },
    "id": "Dp916mcdPkTy",
    "metadata": {},
    "outputId": "3430a1fa-dfc6-4d9f-ba50-ba012121703f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79.94688, 41.326096, 66.86675, 74.269684, 56.64057)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results[0].max_score, search_results[1].max_score, search_results[2].max_score, search_results[10].max_score, search_results[100].max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "V0nWSawgPkTy"
   },
   "outputs": [],
   "source": [
    "# resuming_data_frame = pd.read_json(\"./generated/\"somesetting\".jsonl\", orient=\"records\", lines=True) # just in case more was needed, but didn't want to start from 0 again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O3mKLfzqPkTy",
    "outputId": "12e9c2f4-8537-4c12-f17d-954cc8eddaca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with index: 0\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "\n",
      "Here are two code snippets specified below, modify code snippet No.2 in a way that it includes the logic of code No.1:\n",
      "Code Snippet 1: \"int GENERAL_NAME_cmp(GENERAL_NAME *a, GENERAL_NAME *b)\n",
      "{\n",
      "    int result = -1;\n",
      "\n",
      "    if (!a || !b || a->type != b->type)\n",
      "        return -1;\n",
      "    switch (a->type) {\n",
      "    case GEN_X400:\n",
      "        result = ASN1_TYPE_cmp(a->d.x400Address, b->d.x400Address);\n",
      "        break;\n",
      "\n",
      "    case GEN_EDIPARTY:\n",
      "        result = edipartyname_cmp(a->d.ediPartyName, b->d.ediPartyName);\n",
      "        break;\n",
      "\n",
      "    case GEN_OTHERNAME:\n",
      "        result = OTHERNAME_cmp(a->d.otherName, b->d.otherName);\n",
      "        break;\n",
      "\n",
      "    case GEN_EMAIL:\n",
      "    case GEN_DNS:\n",
      "    case GEN_URI:\n",
      "        result = ASN1_STRING_cmp(a->d.ia5, b->d.ia5);\n",
      "        break;\n",
      "\n",
      "    case GEN_DIRNAME:\n",
      "        result = X509_NAME_cmp(a->d.dirn, b->d.dirn);\n",
      "        break;\n",
      "\n",
      "    case GEN_IPADD:\n",
      "        result = ASN1_OCTET_STRING_cmp(a->d.ip, b->d.ip);\n",
      "        break;\n",
      "\n",
      "    case GEN_RID:\n",
      "        result = OBJ_cmp(a->d.rid, b->d.rid);\n",
      "        break;\n",
      "    }\n",
      "    return result;\n",
      "}\"\n",
      "\n",
      "Code Snippet 2: \"static int edipartyname_cmp(const EDIPARTYNAME *a, const EDIPARTYNAME *b)\n",
      "{\n",
      "    int res;\n",
      "\n",
      "    if (a == NULL || b == NULL) {\n",
      "        /*\n",
      "         * Shouldn't be possible in a valid GENERAL_NAME, but we handle it\n",
      "         * anyway. OTHERNAME_cmp treats NULL != NULL so we do the same here\n",
      "         */\n",
      "        return -1;\n",
      "    }\n",
      "    if (a->nameAssigner == NULL && b->nameAssigner != NULL)\n",
      "        return -1;\n",
      "    if (a->nameAssigner != NULL && b->nameAssigner == NULL)\n",
      "        return 1;\n",
      "    /* If we get here then both have nameAssigner set, or both unset */\n",
      "    if (a->nameAssigner != NULL) {\n",
      "        res = ASN1_STRING_cmp(a->nameAssigner, b->nameAssigner);\n",
      "        if (res != 0)\n",
      "            return res;\n",
      "    }\n",
      "    /*\n",
      "     * partyName is required, so these should never be NULL. We treat it in\n",
      "     * the same way as the a == NULL || b == NULL case above\n",
      "     */\n",
      "    if (a->partyName == NULL || b->partyName == NULL)\n",
      "        return -1;\n",
      "\n",
      "    return ASN1_STRING_cmp(a->partyName, b->partyName);\n",
      "}\"\n",
      "\n",
      "Note that the following lines from the first code snippet have a high priority to be in the final modified code:\n",
      "\n",
      "Lines separated by /~/ : \"{'deleted_lines': ['        result = ASN1_TYPE_cmp(a->d.x400Address, b->d.x400Address);'], 'added_lines': ['        result = ASN1_STRING_cmp(a->d.x400Address, b->d.x400Address);']}\"\n",
      "\n",
      "Put the generated code inside ```C ```. (Do not include comments)\n",
      "\n",
      "assistant\n",
      " GEN_NAME_cmp(GENERAL_NAME *a, GENERAL_NAME *b)\n",
      "{\n",
      "    int result = -1;\n",
      "\n",
      "    if (!a || !b || a->type != b->type)\n",
      "        return -1;\n",
      "    switch (a->type) {\n",
      "    case GEN_X400:\n",
      "        result = ASN1_STRING_cmp(a->d.x400Address, b->d.x400Address);\n",
      "        break;\n",
      "\n",
      "    case GEN_EDIPARTY:\n",
      "        result = edipartyname_cmp(a->d.ediPartyName, b->d.ediPartyName);\n",
      "        break;\n",
      "\n",
      "    case GEN_OTHERNAME:\n",
      "        result = OTHERNAME_cmp(a->d.otherName, b->d.otherName);\n",
      "        break;\n",
      "\n",
      "    case GEN_EMAIL:\n",
      "    case GEN_DNS:\n",
      "    case GEN_URI:\n",
      "        result = ASN1_STRING_cmp(a->d.ia5, b->d.ia5);\n",
      "        break;\n",
      "\n",
      "    case GEN_DIRNAME:\n",
      "        result = X509_NAME_cmp(a->d.dirn, b->d.dirn);\n",
      "        break;\n",
      "\n",
      "    case GEN_IPADD:\n",
      "        result = ASN1_OCTET_STRING_cmp(a->d.ip, b->d.ip);\n",
      "        break;\n",
      "\n",
      "    case GEN_RID:\n",
      "        result = OBJ_cmp(a->d.rid, b->d.rid);\n",
      "        break;\n",
      "    }\n",
      "    return result;\n",
      "}\n",
      "\n",
      "static int edipartyname_cmp(const EDIPARTYNAME *a, const EDIPARTYNAME *b)\n",
      "{\n",
      "    int res;\n",
      "\n",
      "    if (a == NULL || b == NULL) {\n",
      "        /*\n",
      "         * Shouldn't be possible in a valid GENERAL_NAME, but we handle it\n",
      "         * anyway. OTHERNAME_cmp treats NULL != NULL so we do the same here\n",
      "         */\n",
      "        return -1;\n",
      "    }\n",
      "    if (a->nameAssigner == NULL && b->nameAssigner != NULL)\n",
      "        return -1;\n",
      "    if (a->nameAssigner != NULL && b->nameAssigner == NULL)\n",
      "        return 1;\n",
      "    /* If we get here then both have nameAssigner set, or both unset */\n",
      "    if (a->nameAssigner != NULL) {\n",
      "        res = ASN1_STRING_cmp(a->nameAssigner, b->nameAssigner);\n",
      "        if (res != 0)\n",
      "            return res;\n",
      "    }\n",
      "    /*\n",
      "     * partyName is required, so these should never be NULL. We treat it in\n",
      "     * the same way as the a == NULL || b == NULL case above\n",
      "     */\n",
      "    if (a->partyName == NULL || b->partyName == NULL)\n",
      "        return -1;\n",
      "\n",
      "    return ASN1_STRING_cmp(a->partyName, b->partyName);\n",
      "}\n",
      "start_index\n",
      "2442\n",
      "end_index\n",
      "2443\n",
      "\n",
      "code\n",
      "Success!\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "\n",
      "Here are two code snippets specified below, modify code snippet No.2 in a way that it includes the logic of code No.1:\n",
      "Code Snippet 1: \"static int\n",
      "ProcPseudoramiXGetScreenSize(ClientPtr client)\n",
      "{\n",
      "    REQUEST(xPanoramiXGetScreenSizeReq);\n",
      "    WindowPtr pWin;\n",
      "    xPanoramiXGetScreenSizeReply rep;\n",
      "    register int rc;\n",
      "\n",
      "    TRACE;\n",
      "\n",
      "    if (stuff->screen >= pseudoramiXNumScreens)\n",
      "      return BadMatch;\n",
      "\n",
      "    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);\n",
      "    rc = dixLookupWindow(&pWin, stuff->window, client, DixGetAttrAccess);\n",
      "    if (rc != Success)\n",
      "        return rc;\n",
      "\n",
      "    rep.type = X_Reply;\n",
      "    rep.length = 0;\n",
      "    rep.sequenceNumber = client->sequence;\n",
      "    /* screen dimensions */\n",
      "    rep.width = pseudoramiXScreens[stuff->screen].w;\n",
      "    // was screenInfo.screens[stuff->screen]->width;\n",
      "    rep.height = pseudoramiXScreens[stuff->screen].h;\n",
      "    // was screenInfo.screens[stuff->screen]->height;\n",
      "    rep.window = stuff->window;\n",
      "    rep.screen = stuff->screen;\n",
      "    if (client->swapped) {\n",
      "        swaps(&rep.sequenceNumber);\n",
      "        swapl(&rep.length);\n",
      "        swapl(&rep.width);\n",
      "        swapl(&rep.height);\n",
      "        swapl(&rep.window);\n",
      "        swapl(&rep.screen);\n",
      "    }\n",
      "    WriteToClient(client, sizeof(xPanoramiXGetScreenSizeReply),&rep);\n",
      "    return Success;\n",
      "}\"\n",
      "\n",
      "Code Snippet 2: \"static int\n",
      "SProcPseudoramiXIsActive(ClientPtr client)\n",
      "{\n",
      "    REQUEST(xXineramaIsActiveReq);\n",
      "\n",
      "    TRACE;\n",
      "\n",
      "    swaps(&stuff->length);\n",
      "    REQUEST_SIZE_MATCH(xXineramaIsActiveReq);\n",
      "    return ProcPseudoramiXIsActive(client);\n",
      "}\"\n",
      "\n",
      "Note that the following lines from the first code snippet have a high priority to be in the final modified code:\n",
      "\n",
      "Lines separated by /~/ : \"{'deleted_lines': ['    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);'], 'added_lines': ['    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);', '']}\"\n",
      "\n",
      "Put the generated code inside ```C ```. (Do not include comments)\n",
      "\n",
      "assistant\n",
      "```C\n",
      "static int\n",
      "ProcPseudoramiXGetScreenSize(ClientPtr client)\n",
      "{\n",
      "    REQUEST(xPanoramiXGetScreenSizeReq);\n",
      "    WindowPtr pWin;\n",
      "    xPanoramiXGetScreenSizeReply rep;\n",
      "    register int rc;\n",
      "\n",
      "    TRACE;\n",
      "\n",
      "    if (stuff->screen >= pseudoramiXNumScreens)\n",
      "      return BadMatch;\n",
      "\n",
      "    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);\n",
      "    rc = dixLookupWindow(&pWin, stuff->window, client, DixGetAttrAccess);\n",
      "    if (rc != Success)\n",
      "        return rc;\n",
      "\n",
      "    rep.type = X_Reply;\n",
      "    rep.length = 0;\n",
      "    rep.sequenceNumber = client->sequence;\n",
      "    /* screen dimensions */\n",
      "    rep.width = pseudoramiXScreens[stuff->screen].w;\n",
      "    // was screenInfo.screens[stuff->screen]->width;\n",
      "    rep.height = pseudoramiXScreens[stuff->screen].h;\n",
      "    // was screenInfo.screens[stuff->screen]->height;\n",
      "    rep.window = stuff->window;\n",
      "    rep.screen = stuff->screen;\n",
      "    if (client->swapped) {\n",
      "        swaps(&rep.sequenceNumber);\n",
      "        swapl(&rep.length);\n",
      "        swapl(&rep.width);\n",
      "        swapl(&rep.height);\n",
      "        swapl(&rep.window);\n",
      "        swapl(&rep.screen);\n",
      "    }\n",
      "    WriteToClient(client, sizeof(xPanoramiXGetScreenSizeReply),&rep);\n",
      "    return Success;\n",
      "}\n",
      "\n",
      "static int\n",
      "SProcPseudoramiXIsActive(ClientPtr client)\n",
      "{\n",
      "    REQUEST(xXineramaIsActiveReq);\n",
      "\n",
      "    TRACE;\n",
      "\n",
      "    swaps(&stuff->length);\n",
      "    REQUEST_SIZE_MATCH(xXineramaIsActiveReq);\n",
      "    return ProcPseudoramiXIsActive(client);\n",
      "}\n",
      "```\n",
      "```C\n",
      "static int\n",
      "ProcPseudoramiXGetScreenSize(ClientPtr client)\n",
      "{\n",
      "    REQUEST(xPanoramiXGetScreenSizeReq);\n",
      "    WindowPtr pWin;\n",
      "    xPanoramiXGetScreenSizeReply rep;\n",
      "    register int rc;\n",
      "\n",
      "    TRACE;\n",
      "\n",
      "    if (stuff->screen >= pseudoramiXNumScreens)\n",
      "      return BadMatch;\n",
      "\n",
      "    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);\n",
      "    rc = dixLookupWindow(&pWin, stuff->window, client, DixGetAttrAccess);\n",
      "    if (rc != Success)\n",
      "        return rc;\n",
      "\n",
      "    rep.type = X_Reply;\n",
      "    rep.length = 0;\n",
      "    rep.sequenceNumber = client->sequence;\n",
      "    /* screen dimensions */\n",
      "    rep.width = pseudoramiXScreens[stuff->screen].w;\n",
      "    // was screenInfo.screens[stuff->screen]->width;\n",
      "    rep.height = pseudoramiXScreens[stuff->screen].h;\n",
      "    // was screenInfo.screens[stuff->screen]->height;\n",
      "    rep.window = stuff->window;\n",
      "    rep.screen = stuff->screen;\n",
      "    if (client->swapped) {\n",
      "        swaps(&rep.sequenceNumber);\n",
      "        swapl(&rep.length);\n",
      "        swapl(&rep.width);\n",
      "        swapl(&rep.height);\n",
      "        swapl(&rep.window);\n",
      "        swapl(&rep.screen);\n",
      "    }\n",
      "    WriteToClient(client, sizeof(xPanoramiXGetScreenSizeReply),&rep);\n",
      "    return Success;\n",
      "}\n",
      "\n",
      "static int\n",
      "SProcPseudoramiXIsActive(ClientPtr client)\n",
      "{\n",
      "    REQUEST(xXineramaIsActiveReq);\n",
      "\n",
      "    TRACE;\n",
      "\n",
      "    swaps(&stuff->length);\n",
      "    REQUEST_SIZE_MATCH(xXineramaIsActiveReq);\n",
      "    return ProcPseudoramiXIsActive(client);\n",
      "}\n",
      "```\n",
      "```C\n",
      "static int\n",
      "ProcPseudoramiXGetScreenSize(ClientPtr client)\n",
      "{\n",
      "    REQUEST(xPanoramiXGetScreenSizeReq);\n",
      "    WindowPtr pWin;\n",
      "    xPanoramiXGetScreenSizeReply rep;\n",
      "    register int rc;\n",
      "\n",
      "    TRACE;\n",
      "\n",
      "    if (stuff->screen >= pseudoramiXNumScreens)\n",
      "      return BadMatch;\n",
      "\n",
      "    REQUEST_SIZE_MATCH(xPanoramiXGetScreenSizeReq);\n",
      "    rc = dixLookupWindow(&pWin, stuff->window, client, DixGetAttrAccess);\n",
      "    if (rc != Success)\n",
      "        return rc;\n",
      "\n",
      "    rep.type = X_Reply;\n",
      "    rep.length = 0;\n",
      "    rep.sequenceNumber = client->sequence;\n",
      "    /* screen dimensions */\n",
      "    rep.width = pseudoramiXScreens[stuff->screen].w;\n",
      "    // was screenInfo.screens[stuff->screen]->width;\n",
      "    rep.height = pseudoramiXScreens[stuff->screen].h;\n",
      "    // was screenInfo.screens[stuff->screen]->height;\n",
      "    rep.window = stuff->window;\n",
      "    rep.screen = stuff->screen;\n",
      "    if (client->swapped) {\n",
      "        swaps(&rep.sequenceNumber);\n",
      "        swapl(&rep.length);\n",
      "        swapl(&rep.width);\n",
      "        swapl(&rep.height);\n",
      "        swapl(&rep.window);\n",
      "        swapl(&rep.screen);\n",
      "    }\n",
      "    WriteToClient(client, sizeof(x\n",
      "start_index\n",
      "1876\n",
      "end_index\n",
      "1877\n",
      "\n",
      "code\n",
      "Success!\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "\n",
      "Here are two code snippets specified below, modify code snippet No.2 in a way that it includes the logic of code No.1:\n",
      "Code Snippet 1: \"bool MessageReceiver::proc_Submsg_Data(\n",
      "        CDRMessage_t* msg,\n",
      "        SubmessageHeader_t* smh,\n",
      "        EntityId_t& writerID) const\n",
      "{\n",
      "    eprosima::shared_lock<eprosima::shared_mutex> guard(mtx_);\n",
      "\n",
      "    //READ and PROCESS\n",
      "    if (smh->submessageLength < RTPSMESSAGE_DATA_MIN_LENGTH)\n",
      "    {\n",
      "        EPROSIMA_LOG_INFO(RTPS_MSG_IN, IDSTRING \"Too short submessage received, ignoring\");\n",
      "        return false;\n",
      "    }\n",
      "    //Fill flags bool values\n",
      "    bool endiannessFlag = (smh->flags & BIT(0)) != 0;\n",
      "    bool inlineQosFlag = (smh->flags & BIT(1)) != 0;\n",
      "    bool dataFlag = (smh->flags & BIT(2)) != 0;\n",
      "    bool keyFlag = (smh->flags & BIT(3)) != 0;\n",
      "    if (keyFlag && dataFlag)\n",
      "    {\n",
      "        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Message received with Data and Key Flag set, ignoring\");\n",
      "        return false;\n",
      "    }\n",
      "\n",
      "    //Assign message endianness\n",
      "    if (endiannessFlag)\n",
      "    {\n",
      "        msg->msg_endian = LITTLEEND;\n",
      "    }\n",
      "    else\n",
      "    {\n",
      "        msg->msg_endian = BIGEND;\n",
      "    }\n",
      "\n",
      "    //Extra flags don't matter now. Avoid those bytes\n",
      "    msg->pos += 2;\n",
      "\n",
      "    bool valid = true;\n",
      "    int16_t octetsToInlineQos = 0;\n",
      "    valid &= CDRMessage::readInt16(msg, &octetsToInlineQos); //it should be 16 in this implementation\n",
      "\n",
      "    //reader and writer ID\n",
      "    RTPSReader* first_reader = nullptr;\n",
      "    EntityId_t readerID;\n",
      "    valid &= CDRMessage::readEntityId(msg, &readerID);\n",
      "\n",
      "    //WE KNOW THE READER THAT THE MESSAGE IS DIRECTED TO SO WE LOOK FOR IT:\n",
      "    if (!willAReaderAcceptMsgDirectedTo(readerID, first_reader))\n",
      "    {\n",
      "        return false;\n",
      "    }\n",
      "\n",
      "    //FOUND THE READER.\n",
      "    //We ask the reader for a cachechange to store the information.\n",
      "    CacheChange_t ch;\n",
      "    ch.kind = ALIVE;\n",
      "    ch.writerGUID.guidPrefix = source_guid_prefix_;\n",
      "    valid &= CDRMessage::readEntityId(msg, &ch.writerGUID.entityId);\n",
      "\n",
      "    writerID = ch.writerGUID.entityId;\n",
      "\n",
      "    //Get sequence number\n",
      "    valid &= CDRMessage::readSequenceNumber(msg, &ch.sequenceNumber);\n",
      "\n",
      "    if (!valid)\n",
      "    {\n",
      "        return false;\n",
      "    }\n",
      "\n",
      "    if (ch.sequenceNumber <= SequenceNumber_t())\n",
      "    {\n",
      "        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Invalid message received, bad sequence Number\");\n",
      "        return false;\n",
      "    }\n",
      "\n",
      "    //Jump ahead if more parameters are before inlineQos (not in this version, maybe if further minor versions.)\n",
      "    if (octetsToInlineQos > RTPSMESSAGE_OCTETSTOINLINEQOS_DATASUBMSG)\n",
      "    {\n",
      "        msg->pos += (octetsToInlineQos - RTPSMESSAGE_OCTETSTOINLINEQOS_DATASUBMSG);\n",
      "        if (msg->pos > msg->length)\n",
      "        {\n",
      "            EPROSIMA_LOG_WARNING(RTPS_MSG_IN,\n",
      "                    IDSTRING \"Invalid jump through msg, msg->pos \" << msg->pos << \" > msg->length \" << msg->length);\n",
      "            return false;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    uint32_t inlineQosSize = 0;\n",
      "\n",
      "    if (inlineQosFlag)\n",
      "    {\n",
      "        if (!ParameterList::updateCacheChangeFromInlineQos(ch, msg, inlineQosSize))\n",
      "        {\n",
      "            EPROSIMA_LOG_INFO(RTPS_MSG_IN, IDSTRING \"SubMessage Data ERROR, Inline Qos ParameterList error\");\n",
      "            return false;\n",
      "        }\n",
      "        ch.inline_qos.data = &msg->buffer[msg->pos - inlineQosSize];\n",
      "        ch.inline_qos.max_size = inlineQosSize;\n",
      "        ch.inline_qos.length = inlineQosSize;\n",
      "        ch.inline_qos.encapsulation = endiannessFlag ? PL_CDR_LE : PL_CDR_BE;\n",
      "        ch.inline_qos.pos = 0;\n",
      "    }\n",
      "\n",
      "    if (dataFlag || keyFlag)\n",
      "    {\n",
      "        uint32_t payload_size;\n",
      "        payload_size = smh->submessageLength -\n",
      "                (RTPSMESSAGE_DATA_EXTRA_INLINEQOS_SIZE + octetsToInlineQos + inlineQosSize);\n",
      "\n",
      "        if (dataFlag)\n",
      "        {\n",
      "            uint32_t next_pos = msg->pos + payload_size;\n",
      "            if (msg->length >= next_pos && payload_size > 0)\n",
      "            {\n",
      "                ch.serializedPayload.data = &msg->buffer[msg->pos];\n",
      "                ch.serializedPayload.length = payload_size;\n",
      "                ch.serializedPayload.max_size = payload_size;\n",
      "                msg->pos = next_pos;\n",
      "            }\n",
      "            else\n",
      "            {\n",
      "                EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Serialized Payload value invalid or larger than maximum allowed size\"\n",
      "                        \"(\" << payload_size << \"/\" << (msg->length - msg->pos) << \")\");\n",
      "                return false;\n",
      "            }\n",
      "        }\n",
      "        else if (keyFlag)\n",
      "        {\n",
      "            if (payload_size <= 0)\n",
      "            {\n",
      "                EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Serialized Payload value invalid (\" << payload_size << \")\");\n",
      "                return false;\n",
      "            }\n",
      "\n",
      "            if (payload_size <= PARAMETER_KEY_HASH_LENGTH)\n",
      "            {\n",
      "                memcpy(ch.instanceHandle.value, &msg->buffer[msg->pos], payload_size);\n",
      "            }\n",
      "            else\n",
      "            {\n",
      "                EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Ignoring Serialized Payload for too large key-only data (\" <<\n",
      "                        payload_size << \")\");\n",
      "            }\n",
      "            msg->pos += payload_size;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    // Set sourcetimestamp\n",
      "    if (have_timestamp_)\n",
      "    {\n",
      "        ch.sourceTimestamp = timestamp_;\n",
      "    }\n",
      "\n",
      "    EPROSIMA_LOG_INFO(RTPS_MSG_IN, IDSTRING \"from Writer \" << ch.writerGUID << \"; possible RTPSReader entities: \" <<\n",
      "            associated_readers_.size());\n",
      "\n",
      "    //Look for the correct reader to add the change\n",
      "    process_data_message_function_(readerID, ch);\n",
      "\n",
      "    IPayloadPool* payload_pool = ch.payload_owner();\n",
      "    if (payload_pool)\n",
      "    {\n",
      "        payload_pool->release_payload(ch);\n",
      "    }\n",
      "\n",
      "    //TODO(Ricardo) If an exception is thrown (ex, by fastcdr), these lines are not executed -> segmentation fault\n",
      "    ch.serializedPayload.data = nullptr;\n",
      "    ch.inline_qos.data = nullptr;\n",
      "\n",
      "    EPROSIMA_LOG_INFO(RTPS_MSG_IN, IDSTRING \"Sub Message DATA processed\");\n",
      "    return true;\n",
      "}\"\n",
      "\n",
      "Code Snippet 2: \"bool MessageReceiver::proc_Submsg_InfoSRC(\n",
      "        CDRMessage_t* msg,\n",
      "        SubmessageHeader_t* smh)\n",
      "{\n",
      "    std::lock_guard<eprosima::shared_mutex> guard(mtx_);\n",
      "\n",
      "    bool endiannessFlag = (smh->flags & BIT(0)) != 0;\n",
      "    //bool timeFlag = smh->flags & BIT(1) ? true : false;\n",
      "    //Assign message endianness\n",
      "    if (endiannessFlag)\n",
      "    {\n",
      "        msg->msg_endian = LITTLEEND;\n",
      "    }\n",
      "    else\n",
      "    {\n",
      "        msg->msg_endian = BIGEND;\n",
      "    }\n",
      "    if (smh->submessageLength == INFO_SRC_SUBMSG_LENGTH)\n",
      "    {\n",
      "        //AVOID FIRST 4 BYTES:\n",
      "        msg->pos += 4;\n",
      "        CDRMessage::readOctet(msg, &source_version_.m_major);\n",
      "        CDRMessage::readOctet(msg, &source_version_.m_minor);\n",
      "        CDRMessage::readData(msg, &source_vendor_id_[0], 2);\n",
      "        CDRMessage::readData(msg, source_guid_prefix_.value, GuidPrefix_t::size);\n",
      "        EPROSIMA_LOG_INFO(RTPS_MSG_IN, IDSTRING \"SRC RTPSParticipant is now: \" << source_guid_prefix_);\n",
      "        return true;\n",
      "    }\n",
      "    return false;\n",
      "}\"\n",
      "\n",
      "Note that the following lines from the first code snippet have a high priority to be in the final modified code:\n",
      "\n",
      "Lines separated by /~/ : \"{'deleted_lines': [], 'added_lines': ['                ch.serializedPayload.data = nullptr;', '                ch.inline_qos.data = nullptr;', '                ch.serializedPayload.data = nullptr;', '                ch.inline_qos.data = nullptr;']}\"\n",
      "\n",
      "Put the generated code inside ```C ```. (Do not include comments)\n",
      "\n",
      "assistant\n",
      "����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������\n",
      "start_index\n",
      "7258\n",
      "end_index\n",
      "7259\n",
      "\n",
      "code\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "\n",
      "Here are two code snippets specified below, modify code snippet No.2 in a way that it includes the logic of code No.1:\n",
      "Code Snippet 1: \"void x25_kill_by_neigh(struct x25_neigh *nb)\n",
      "{\n",
      "\tstruct sock *s;\n",
      "\n",
      "\twrite_lock_bh(&x25_list_lock);\n",
      "\n",
      "\tsk_for_each(s, &x25_list)\n",
      "\t\tif (x25_sk(s)->neighbour == nb)\n",
      "\t\t\tx25_disconnect(s, ENETUNREACH, 0, 0);\n",
      "\n",
      "\twrite_unlock_bh(&x25_list_lock);\n",
      "\n",
      "\t/* Remove any related forwards */\n",
      "\tx25_clear_forward_by_dev(nb->dev);\n",
      "}\"\n",
      "\n",
      "Code Snippet 2: \"int x25_addr_aton(unsigned char *p, struct x25_address *called_addr,\n",
      "\t\t  struct x25_address *calling_addr)\n",
      "{\n",
      "\tunsigned int called_len, calling_len;\n",
      "\tchar *called, *calling;\n",
      "\tint i;\n",
      "\n",
      "\tcalled  = called_addr->x25_addr;\n",
      "\tcalling = calling_addr->x25_addr;\n",
      "\n",
      "\tcalled_len  = strlen(called);\n",
      "\tcalling_len = strlen(calling);\n",
      "\n",
      "\t*p++ = (calling_len << 4) | (called_len << 0);\n",
      "\n",
      "\tfor (i = 0; i < (called_len + calling_len); i++) {\n",
      "\t\tif (i < called_len) {\n",
      "\t\t\tif (i % 2 != 0) {\n",
      "\t\t\t\t*p |= (*called++ - '0') << 0;\n",
      "\t\t\t\tp++;\n",
      "\t\t\t} else {\n",
      "\t\t\t\t*p = 0x00;\n",
      "\t\t\t\t*p |= (*called++ - '0') << 4;\n",
      "\t\t\t}\n",
      "\t\t} else {\n",
      "\t\t\tif (i % 2 != 0) {\n",
      "\t\t\t\t*p |= (*calling++ - '0') << 0;\n",
      "\t\t\t\tp++;\n",
      "\t\t\t} else {\n",
      "\t\t\t\t*p = 0x00;\n",
      "\t\t\t\t*p |= (*calling++ - '0') << 4;\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\treturn 1 + (called_len + calling_len + 1) / 2;\n",
      "}\"\n",
      "\n",
      "Note that the following lines from the first code snippet have a high priority to be in the final modified code:\n",
      "\n",
      "Lines separated by /~/ : \"{'deleted_lines': ['\\tsk_for_each(s, &x25_list)', '\\t\\tif (x25_sk(s)->neighbour == nb)', ''], 'added_lines': ['\\tsk_for_each(s, &x25_list) {', '\\t\\tif (x25_sk(s)->neighbour == nb) {', '\\t\\t\\twrite_unlock_bh(&x25_list_lock);', '\\t\\t\\tlock_sock(s);', '\\t\\t\\trelease_sock(s);', '\\t\\t\\twrite_lock_bh(&x25_list_lock);', '\\t\\t}', '\\t}']}\"\n",
      "\n",
      "Put the generated code inside ```C ```. (Do not include comments)\n",
      "\n",
      "assistant\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "Ḿ\n",
      "\n",
      "start_index\n",
      "1788\n",
      "end_index\n",
      "1789\n",
      "\n",
      "code\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "\n",
      "Here are two code snippets specified below, modify code snippet No.2 in a way that it includes the logic of code No.1:\n",
      "Code Snippet 1: \"static GF_AVCConfig *AVC_DuplicateConfig(GF_AVCConfig *cfg)\n",
      "{\n",
      "\tu32 i, count;\n",
      "\tGF_AVCConfigSlot *p1, *p2;\n",
      "\tGF_AVCConfig *cfg_new = gf_odf_avc_cfg_new();\n",
      "\tcfg_new->AVCLevelIndication = cfg->AVCLevelIndication;\n",
      "\tcfg_new->AVCProfileIndication = cfg->AVCProfileIndication;\n",
      "\tcfg_new->configurationVersion = cfg->configurationVersion;\n",
      "\tcfg_new->nal_unit_size = cfg->nal_unit_size;\n",
      "\tcfg_new->profile_compatibility = cfg->profile_compatibility;\n",
      "\tcfg_new->complete_representation = cfg->complete_representation;\n",
      "\tcfg_new->chroma_bit_depth = cfg->chroma_bit_depth;\n",
      "\tcfg_new->luma_bit_depth = cfg->luma_bit_depth;\n",
      "\tcfg_new->chroma_format = cfg->chroma_format;\n",
      "\n",
      "\tcount = gf_list_count(cfg->sequenceParameterSets);\n",
      "\tfor (i=0; i<count; i++) {\n",
      "\t\tp1 = (GF_AVCConfigSlot*)gf_list_get(cfg->sequenceParameterSets, i);\n",
      "\t\tp2 = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));\n",
      "\t\tp2->size = p1->size;\n",
      "\t\tp2->id = p1->id;\n",
      "\t\tp2->data = (char *)gf_malloc(sizeof(char)*p1->size);\n",
      "\t\tmemcpy(p2->data, p1->data, sizeof(char)*p1->size);\n",
      "\t\tgf_list_add(cfg_new->sequenceParameterSets, p2);\n",
      "\t}\n",
      "\n",
      "\tcount = gf_list_count(cfg->pictureParameterSets);\n",
      "\tfor (i=0; i<count; i++) {\n",
      "\t\tp1 = (GF_AVCConfigSlot*)gf_list_get(cfg->pictureParameterSets, i);\n",
      "\t\tp2 = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));\n",
      "\t\tp2->size = p1->size;\n",
      "\t\tp2->id = p1->id;\n",
      "\t\tp2->data = (char*)gf_malloc(sizeof(char)*p1->size);\n",
      "\t\tmemcpy(p2->data, p1->data, sizeof(char)*p1->size);\n",
      "\t\tgf_list_add(cfg_new->pictureParameterSets, p2);\n",
      "\t}\n",
      "\n",
      "\tif (cfg->sequenceParameterSetExtensions) {\n",
      "\t\tcfg_new->sequenceParameterSetExtensions = gf_list_new();\n",
      "\t\tcount = gf_list_count(cfg->sequenceParameterSetExtensions);\n",
      "\t\tfor (i=0; i<count; i++) {\n",
      "\t\t\tp1 = (GF_AVCConfigSlot*)gf_list_get(cfg->sequenceParameterSetExtensions, i);\n",
      "\t\t\tp2 = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));\n",
      "\t\t\tp2->size = p1->size;\n",
      "\t\t\tp2->id = p1->id;\n",
      "\t\t\tp2->data = (char*)gf_malloc(sizeof(char)*p1->size);\n",
      "\t\t\tmemcpy(p2->data, p1->data, sizeof(char)*p1->size);\n",
      "\t\t\tgf_list_add(cfg_new->sequenceParameterSetExtensions, p2);\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn cfg_new;\n",
      "}\"\n",
      "\n",
      "Code Snippet 2: \"GF_Err vpcc_Write(GF_Box *s, GF_BitStream *bs)\n",
      "{\n",
      "\tGF_Err e;\n",
      "\tGF_VPConfigurationBox *ptr = (GF_VPConfigurationBox *) s;\n",
      "\tif (!s) return GF_BAD_PARAM;\n",
      "\tif (!ptr->config) return GF_OK;\n",
      "\n",
      "\te = gf_isom_full_box_write(s, bs);\n",
      "\tif (e) return e;\n",
      "\t\n",
      "\treturn gf_odf_vp_cfg_write_bs(ptr->config, bs, ptr->version == 0);\n",
      "}\"\n",
      "\n",
      "Note that the following lines from the first code snippet have a high priority to be in the final modified code:\n",
      "\n",
      "Lines separated by /~/ : \"{'deleted_lines': ['\\tGF_AVCConfig *cfg_new = gf_odf_avc_cfg_new();'], 'added_lines': ['\\tGF_AVCConfig *cfg_new;', '\\tif (!cfg)', '\\t\\treturn NULL;', '\\tcfg_new = gf_odf_avc_cfg_new();']}\"\n",
      "\n",
      "Put the generated code inside ```C ```. (Do not include comments)\n",
      "\n",
      "assistant\n",
      "```C\n",
      "static GF_AVCConfig *AVC_DuplicateConfig(GF_AVCConfig *cfg)\n",
      "{\n",
      "\tu32 i, count;\n",
      "\tGF_AVCConfigSlot *p1, *p2;\n",
      "\tGF_AVCConfig *cfg_new = gf_odf_avc_cfg_new();\n",
      "\tcfg_new->AVCLevelIndication = cfg->AVCLevelIndication;\n",
      "\tcfg_new->AVCProfileIndication = cfg->AVCProfileIndication;\n",
      "\tcfg_new->configurationVersion = cfg->configurationVersion;\n",
      "\tcfg_new->nal_unit_size = cfg->nal_unit_size;\n",
      "\tcfg_new->profile_compatibility = cfg->profile_compatibility;\n",
      "\tcfg_new->complete_representation = cfg->complete_representation;\n",
      "\tcfg_new->chroma_bit_depth = cfg->chroma_bit_depth;\n",
      "\tcfg_new->luma_bit_depth = cfg->luma_bit_depth;\n",
      "\tcfg_new->chroma_format = cfg->chroma_format;\n",
      "\n",
      "\tcount = gf_list_count(cfg->sequenceParameterSets);\n",
      "\tfor (i=0; i<count; i++) {\n",
      "\t\tp1 = (GF_AVCConfigSlot*)gf_list_get(cfg->sequenceParameterSets, i);\n",
      "\t\tp2 = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));\n",
      "\t\tp2->size = p1->size;\n",
      "\t\tp2->id = p1->id;\n",
      "\t\tp2->data = (char *)gf_malloc(sizeof(char)*p1->size);\n",
      "\t\tmemcpy(p2->data, p1->data, sizeof(char)*p1->size);\n",
      "\t\tgf_list_add(cfg_new->sequenceParameterSets, p2);\n",
      "\t}\n",
      "\n",
      "\tcount = gf_list_count(cfg->pictureParameterSets);\n",
      "\tfor (i=0; i<count; i++) {\n",
      "\t\tp1 = (GF_AVCConfigSlot*)gf_list_get(cfg->pictureParameterSets, i);\n",
      "\t\tp2 = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));\n",
      "\t\tp2->size = p1->size;\n",
      "\t\tp2->id = p1->id;\n",
      "\t\tp2->data = (char*)gf_malloc(sizeof(char)*p1->size);\n",
      "\t\tmemcpy(p2->data, p1->data, sizeof(char)*p1->size);\n",
      "\t\tgf_list_add(cfg_new->pictureParameterSets, p2);\n",
      "\t}\n",
      "\n",
      "\tif (cfg->sequenceParameterSetExtensions) {\n",
      "\t\tcfg_new->sequenceParameterSetExtensions = gf_list_new();\n",
      "\t\tcount = gf_list_count(cfg->sequenceParameterSetExtensions);\n",
      "\t\tfor (i=0; i<count; i++) {\n",
      "\t\t\tp1 = (GF_AVCConfigSlot*)gf_list_get(cfg->sequenceParameterSetExtensions, i);\n",
      "\t\t\tp2 = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));\n",
      "\t\t\tp2->size = p1->size;\n",
      "\t\t\tp2->id = p1->id;\n",
      "\t\t\tp2->data = (char*)gf_malloc(sizeof(char)*p1->size);\n",
      "\t\t\tmemcpy(p2->data, p1->data, sizeof(char)*p1->size);\n",
      "\t\t\tgf_list_add(cfg_new->sequenceParameterSetExtensions, p2);\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn cfg_new;\n",
      "}\n",
      "\n",
      "GF_Err vpcc_Write(GF_Box *s, GF_BitStream *bs)\n",
      "{\n",
      "\tGF_Err e;\n",
      "\tGF_VPConfigurationBox *ptr = (GF_VPConfigurationBox *) s;\n",
      "\tif (!s) return GF_BAD_PARAM;\n",
      "\tif (!ptr->config) return GF_OK;\n",
      "\n",
      "\te = gf_isom_full_box_write(s, bs);\n",
      "\tif (e) return e;\n",
      "\t\n",
      "\treturn gf_odf_vp_cfg_write_bs(ptr->config, bs, ptr->version == 0);\n",
      "}\n",
      "```\n",
      "start_index\n",
      "2928\n",
      "end_index\n",
      "2929\n",
      "\n",
      "code\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "\n",
      "Here are two code snippets specified below, modify code snippet No.2 in a way that it includes the logic of code No.1:\n",
      "Code Snippet 1: \"int\n",
      "main(int ac, char **av)\n",
      "{\n",
      "\tint c_flag = 0, d_flag = 0, D_flag = 0, k_flag = 0, s_flag = 0;\n",
      "\tint sock, ch, result, saved_errno;\n",
      "\tchar *shell, *format, *pidstr, *agentsocket = NULL;\n",
      "\tstruct rlimit rlim;\n",
      "\textern int optind;\n",
      "\textern char *optarg;\n",
      "\tpid_t pid;\n",
      "\tchar pidstrbuf[1 + 3 * sizeof pid];\n",
      "\tsize_t len;\n",
      "\tmode_t prev_mask;\n",
      "\tint timeout = -1; /* INFTIM */\n",
      "\tstruct pollfd *pfd = NULL;\n",
      "\tsize_t npfd = 0;\n",
      "\tu_int maxfds;\n",
      "\n",
      "\t/* Ensure that fds 0, 1 and 2 are open or directed to /dev/null */\n",
      "\tsanitise_stdfd();\n",
      "\n",
      "\t/* drop */\n",
      "\t(void)setegid(getgid());\n",
      "\t(void)setgid(getgid());\n",
      "\n",
      "\tif (getrlimit(RLIMIT_NOFILE, &rlim) == -1)\n",
      "\t\tfatal(\"%s: getrlimit: %s\", __progname, strerror(errno));\n",
      "\n",
      "#ifdef WITH_OPENSSL\n",
      "\tOpenSSL_add_all_algorithms();\n",
      "#endif\n",
      "\n",
      "\twhile ((ch = getopt(ac, av, \"cDdksE:a:O:P:t:\")) != -1) {\n",
      "\t\tswitch (ch) {\n",
      "\t\tcase 'E':\n",
      "\t\t\tfingerprint_hash = ssh_digest_alg_by_name(optarg);\n",
      "\t\t\tif (fingerprint_hash == -1)\n",
      "\t\t\t\tfatal(\"Invalid hash algorithm \\\"%s\\\"\", optarg);\n",
      "\t\t\tbreak;\n",
      "\t\tcase 'c':\n",
      "\t\t\tif (s_flag)\n",
      "\t\t\t\tusage();\n",
      "\t\t\tc_flag++;\n",
      "\t\t\tbreak;\n",
      "\t\tcase 'k':\n",
      "\t\t\tk_flag++;\n",
      "\t\t\tbreak;\n",
      "\t\tcase 'O':\n",
      "\t\t\tif (strcmp(optarg, \"no-restrict-websafe\") == 0)\n",
      "\t\t\t\trestrict_websafe  = 0;\n",
      "\t\t\telse\n",
      "\t\t\t\tfatal(\"Unknown -O option\");\n",
      "\t\t\tbreak;\n",
      "\t\tcase 'P':\n",
      "\t\t\tif (allowed_providers != NULL)\n",
      "\t\t\t\tfatal(\"-P option already specified\");\n",
      "\t\t\tallowed_providers = xstrdup(optarg);\n",
      "\t\t\tbreak;\n",
      "\t\tcase 's':\n",
      "\t\t\tif (c_flag)\n",
      "\t\t\t\tusage();\n",
      "\t\t\ts_flag++;\n",
      "\t\t\tbreak;\n",
      "\t\tcase 'd':\n",
      "\t\t\tif (d_flag || D_flag)\n",
      "\t\t\t\tusage();\n",
      "\t\t\td_flag++;\n",
      "\t\t\tbreak;\n",
      "\t\tcase 'D':\n",
      "\t\t\tif (d_flag || D_flag)\n",
      "\t\t\t\tusage();\n",
      "\t\t\tD_flag++;\n",
      "\t\t\tbreak;\n",
      "\t\tcase 'a':\n",
      "\t\t\tagentsocket = optarg;\n",
      "\t\t\tbreak;\n",
      "\t\tcase 't':\n",
      "\t\t\tif ((lifetime = convtime(optarg)) == -1) {\n",
      "\t\t\t\tfprintf(stderr, \"Invalid lifetime\\n\");\n",
      "\t\t\t\tusage();\n",
      "\t\t\t}\n",
      "\t\t\tbreak;\n",
      "\t\tdefault:\n",
      "\t\t\tusage();\n",
      "\t\t}\n",
      "\t}\n",
      "\tac -= optind;\n",
      "\tav += optind;\n",
      "\n",
      "\tif (ac > 0 && (c_flag || k_flag || s_flag || d_flag || D_flag))\n",
      "\t\tusage();\n",
      "\n",
      "\tif (allowed_providers == NULL)\n",
      "\t\tallowed_providers = xstrdup(DEFAULT_ALLOWED_PROVIDERS);\n",
      "\n",
      "\tif (ac == 0 && !c_flag && !s_flag) {\n",
      "\t\tshell = getenv(\"SHELL\");\n",
      "\t\tif (shell != NULL && (len = strlen(shell)) > 2 &&\n",
      "\t\t    strncmp(shell + len - 3, \"csh\", 3) == 0)\n",
      "\t\t\tc_flag = 1;\n",
      "\t}\n",
      "\tif (k_flag) {\n",
      "\t\tconst char *errstr = NULL;\n",
      "\n",
      "\t\tpidstr = getenv(SSH_AGENTPID_ENV_NAME);\n",
      "\t\tif (pidstr == NULL) {\n",
      "\t\t\tfprintf(stderr, \"%s not set, cannot kill agent\\n\",\n",
      "\t\t\t    SSH_AGENTPID_ENV_NAME);\n",
      "\t\t\texit(1);\n",
      "\t\t}\n",
      "\t\tpid = (int)strtonum(pidstr, 2, INT_MAX, &errstr);\n",
      "\t\tif (errstr) {\n",
      "\t\t\tfprintf(stderr,\n",
      "\t\t\t    \"%s=\\\"%s\\\", which is not a good PID: %s\\n\",\n",
      "\t\t\t    SSH_AGENTPID_ENV_NAME, pidstr, errstr);\n",
      "\t\t\texit(1);\n",
      "\t\t}\n",
      "\t\tif (kill(pid, SIGTERM) == -1) {\n",
      "\t\t\tperror(\"kill\");\n",
      "\t\t\texit(1);\n",
      "\t\t}\n",
      "\t\tformat = c_flag ? \"unsetenv %s;\\n\" : \"unset %s;\\n\";\n",
      "\t\tprintf(format, SSH_AUTHSOCKET_ENV_NAME);\n",
      "\t\tprintf(format, SSH_AGENTPID_ENV_NAME);\n",
      "\t\tprintf(\"echo Agent pid %ld killed;\\n\", (long)pid);\n",
      "\t\texit(0);\n",
      "\t}\n",
      "\n",
      "\t/*\n",
      "\t * Minimum file descriptors:\n",
      "\t * stdio (3) + listener (1) + syslog (1 maybe) + connection (1) +\n",
      "\t * a few spare for libc / stack protectors / sanitisers, etc.\n",
      "\t */\n",
      "#define SSH_AGENT_MIN_FDS (3+1+1+1+4)\n",
      "\tif (rlim.rlim_cur < SSH_AGENT_MIN_FDS)\n",
      "\t\tfatal(\"%s: file descriptor rlimit %lld too low (minimum %u)\",\n",
      "\t\t    __progname, (long long)rlim.rlim_cur, SSH_AGENT_MIN_FDS);\n",
      "\tmaxfds = rlim.rlim_cur - SSH_AGENT_MIN_FDS;\n",
      "\n",
      "\tparent_pid = getpid();\n",
      "\n",
      "\tif (agentsocket == NULL) {\n",
      "\t\t/* Create private directory for agent socket */\n",
      "\t\tmktemp_proto(socket_dir, sizeof(socket_dir));\n",
      "\t\tif (mkdtemp(socket_dir) == NULL) {\n",
      "\t\t\tperror(\"mkdtemp: private socket dir\");\n",
      "\t\t\texit(1);\n",
      "\t\t}\n",
      "\t\tsnprintf(socket_name, sizeof socket_name, \"%s/agent.%ld\", socket_dir,\n",
      "\t\t    (long)parent_pid);\n",
      "\t} else {\n",
      "\t\t/* Try to use specified agent socket */\n",
      "\t\tsocket_dir[0] = '\\0';\n",
      "\t\tstrlcpy(socket_name, agentsocket, sizeof socket_name);\n",
      "\t}\n",
      "\n",
      "\t/*\n",
      "\t * Create socket early so it will exist before command gets run from\n",
      "\t * the parent.\n",
      "\t */\n",
      "\tprev_mask = umask(0177);\n",
      "\tsock = unix_listener(socket_name, SSH_LISTEN_BACKLOG, 0);\n",
      "\tif (sock < 0) {\n",
      "\t\t/* XXX - unix_listener() calls error() not perror() */\n",
      "\t\t*socket_name = '\\0'; /* Don't unlink any existing file */\n",
      "\t\tcleanup_exit(1);\n",
      "\t}\n",
      "\tumask(prev_mask);\n",
      "\n",
      "\t/*\n",
      "\t * Fork, and have the parent execute the command, if any, or present\n",
      "\t * the socket data.  The child continues as the authentication agent.\n",
      "\t */\n",
      "\tif (D_flag || d_flag) {\n",
      "\t\tlog_init(__progname,\n",
      "\t\t    d_flag ? SYSLOG_LEVEL_DEBUG3 : SYSLOG_LEVEL_INFO,\n",
      "\t\t    SYSLOG_FACILITY_AUTH, 1);\n",
      "\t\tformat = c_flag ? \"setenv %s %s;\\n\" : \"%s=%s; export %s;\\n\";\n",
      "\t\tprintf(format, SSH_AUTHSOCKET_ENV_NAME, socket_name,\n",
      "\t\t    SSH_AUTHSOCKET_ENV_NAME);\n",
      "\t\tprintf(\"echo Agent pid %ld;\\n\", (long)parent_pid);\n",
      "\t\tfflush(stdout);\n",
      "\t\tgoto skip;\n",
      "\t}\n",
      "\tpid = fork();\n",
      "\tif (pid == -1) {\n",
      "\t\tperror(\"fork\");\n",
      "\t\tcleanup_exit(1);\n",
      "\t}\n",
      "\tif (pid != 0) {\t\t/* Parent - execute the given command. */\n",
      "\t\tclose(sock);\n",
      "\t\tsnprintf(pidstrbuf, sizeof pidstrbuf, \"%ld\", (long)pid);\n",
      "\t\tif (ac == 0) {\n",
      "\t\t\tformat = c_flag ? \"setenv %s %s;\\n\" : \"%s=%s; export %s;\\n\";\n",
      "\t\t\tprintf(format, SSH_AUTHSOCKET_ENV_NAME, socket_name,\n",
      "\t\t\t    SSH_AUTHSOCKET_ENV_NAME);\n",
      "\t\t\tprintf(format, SSH_AGENTPID_ENV_NAME, pidstrbuf,\n",
      "\t\t\t    SSH_AGENTPID_ENV_NAME);\n",
      "\t\t\tprintf(\"echo Agent pid %ld;\\n\", (long)pid);\n",
      "\t\t\texit(0);\n",
      "\t\t}\n",
      "\t\tif (setenv(SSH_AUTHSOCKET_ENV_NAME, socket_name, 1) == -1 ||\n",
      "\t\t    setenv(SSH_AGENTPID_ENV_NAME, pidstrbuf, 1) == -1) {\n",
      "\t\t\tperror(\"setenv\");\n",
      "\t\t\texit(1);\n",
      "\t\t}\n",
      "\t\texecvp(av[0], av);\n",
      "\t\tperror(av[0]);\n",
      "\t\texit(1);\n",
      "\t}\n",
      "\t/* child */\n",
      "\tlog_init(__progname, SYSLOG_LEVEL_INFO, SYSLOG_FACILITY_AUTH, 0);\n",
      "\n",
      "\tif (setsid() == -1) {\n",
      "\t\terror(\"setsid: %s\", strerror(errno));\n",
      "\t\tcleanup_exit(1);\n",
      "\t}\n",
      "\n",
      "\t(void)chdir(\"/\");\n",
      "\tif (stdfd_devnull(1, 1, 1) == -1)\n",
      "\t\terror_f(\"stdfd_devnull failed\");\n",
      "\n",
      "\t/* deny core dumps, since memory contains unencrypted private keys */\n",
      "\trlim.rlim_cur = rlim.rlim_max = 0;\n",
      "\tif (setrlimit(RLIMIT_CORE, &rlim) == -1) {\n",
      "\t\terror(\"setrlimit RLIMIT_CORE: %s\", strerror(errno));\n",
      "\t\tcleanup_exit(1);\n",
      "\t}\n",
      "\n",
      "skip:\n",
      "\n",
      "\tcleanup_pid = getpid();\n",
      "\n",
      "#ifdef ENABLE_PKCS11\n",
      "\tpkcs11_init(0);\n",
      "#endif\n",
      "\tnew_socket(AUTH_SOCKET, sock);\n",
      "\tif (ac > 0)\n",
      "\t\tparent_alive_interval = 10;\n",
      "\tidtab_init();\n",
      "\tssh_signal(SIGPIPE, SIG_IGN);\n",
      "\tssh_signal(SIGINT, (d_flag | D_flag) ? cleanup_handler : SIG_IGN);\n",
      "\tssh_signal(SIGHUP, cleanup_handler);\n",
      "\tssh_signal(SIGTERM, cleanup_handler);\n",
      "\n",
      "\tif (pledge(\"stdio rpath cpath unix id proc exec\", NULL) == -1)\n",
      "\t\tfatal(\"%s: pledge: %s\", __progname, strerror(errno));\n",
      "\n",
      "\twhile (1) {\n",
      "\t\tprepare_poll(&pfd, &npfd, &timeout, maxfds);\n",
      "\t\tresult = poll(pfd, npfd, timeout);\n",
      "\t\tsaved_errno = errno;\n",
      "\t\tif (parent_alive_interval != 0)\n",
      "\t\t\tcheck_parent_exists();\n",
      "\t\t(void) reaper();\t/* remove expired keys */\n",
      "\t\tif (result == -1) {\n",
      "\t\t\tif (saved_errno == EINTR)\n",
      "\t\t\t\tcontinue;\n",
      "\t\t\tfatal(\"poll: %s\", strerror(saved_errno));\n",
      "\t\t} else if (result > 0)\n",
      "\t\t\tafter_poll(pfd, npfd, maxfds);\n",
      "\t}\n",
      "\t/* NOTREACHED */\n",
      "}\"\n",
      "\n",
      "Code Snippet 2: \"static void\n",
      "process_remove_smartcard_key(SocketEntry *e)\n",
      "{\n",
      "\tchar *provider = NULL, *pin = NULL, canonical_provider[PATH_MAX];\n",
      "\tint r, success = 0;\n",
      "\tIdentity *id, *nxt;\n",
      "\n",
      "\tdebug2_f(\"entering\");\n",
      "\tif ((r = sshbuf_get_cstring(e->request, &provider, NULL)) != 0 ||\n",
      "\t    (r = sshbuf_get_cstring(e->request, &pin, NULL)) != 0) {\n",
      "\t\terror_fr(r, \"parse\");\n",
      "\t\tgoto send;\n",
      "\t}\n",
      "\tfree(pin);\n",
      "\n",
      "\tif (realpath(provider, canonical_provider) == NULL) {\n",
      "\t\tverbose(\"failed PKCS#11 add of \\\"%.100s\\\": realpath: %s\",\n",
      "\t\t    provider, strerror(errno));\n",
      "\t\tgoto send;\n",
      "\t}\n",
      "\n",
      "\tdebug_f(\"remove %.100s\", canonical_provider);\n",
      "\tfor (id = TAILQ_FIRST(&idtab->idlist); id; id = nxt) {\n",
      "\t\tnxt = TAILQ_NEXT(id, next);\n",
      "\t\t/* Skip file--based keys */\n",
      "\t\tif (id->provider == NULL)\n",
      "\t\t\tcontinue;\n",
      "\t\tif (!strcmp(canonical_provider, id->provider)) {\n",
      "\t\t\tTAILQ_REMOVE(&idtab->idlist, id, next);\n",
      "\t\t\tfree_identity(id);\n",
      "\t\t\tidtab->nentries--;\n",
      "\t\t}\n",
      "\t}\n",
      "\tif (pkcs11_del_provider(canonical_provider) == 0)\n",
      "\t\tsuccess = 1;\n",
      "\telse\n",
      "\t\terror_f(\"pkcs11_del_provider failed\");\n",
      "send:\n",
      "\tfree(provider);\n",
      "\tsend_status(e, success);\n",
      "}\"\n",
      "\n",
      "Note that the following lines from the first code snippet have a high priority to be in the final modified code:\n",
      "\n",
      "Lines separated by /~/ : \"{'deleted_lines': ['\\t\\t\\t\\trestrict_websafe  = 0;'], 'added_lines': ['\\t\\t\\t\\trestrict_websafe = 0;', '\\t\\t\\telse if (strcmp(optarg, \"allow-remote-pkcs11\") == 0)', '\\t\\t\\t\\tremote_add_provider = 1;']}\"\n",
      "\n",
      "Put the generated code inside ```C ```. (Do not include comments)\n",
      "\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "assistant\n",
      "\n",
      "start_index\n",
      "8343\n",
      "end_index\n",
      "8344\n",
      "\n",
      "code\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "\n",
      "Here are two code snippets specified below, modify code snippet No.2 in a way that it includes the logic of code No.1:\n",
      "Code Snippet 1: \"void\n",
      "TIFFCleanup(TIFF* tif)\n",
      "{\n",
      "\t/*\n",
      "         * Flush buffered data and directory (if dirty).\n",
      "         */\n",
      "\tif (tif->tif_mode != O_RDONLY)\n",
      "\t\tTIFFFlush(tif);\n",
      "\t(*tif->tif_cleanup)(tif);\n",
      "\tTIFFFreeDirectory(tif);\n",
      "\n",
      "\tif (tif->tif_dirlist)\n",
      "\t\t_TIFFfree(tif->tif_dirlist);\n",
      "\n",
      "\t/*\n",
      "         * Clean up client info links.\n",
      "         */\n",
      "\twhile( tif->tif_clientinfo )\n",
      "\t{\n",
      "\t\tTIFFClientInfoLink *psLink = tif->tif_clientinfo;\n",
      "\n",
      "\t\ttif->tif_clientinfo = psLink->next;\n",
      "\t\t_TIFFfree( psLink->name );\n",
      "\t\t_TIFFfree( psLink );\n",
      "\t}\n",
      "\n",
      "\tif (tif->tif_rawdata && (tif->tif_flags&TIFF_MYBUFFER))\n",
      "\t\t_TIFFfree(tif->tif_rawdata);\n",
      "\tif (isMapped(tif))\n",
      "\t\tTIFFUnmapFileContents(tif, tif->tif_base, (toff_t)tif->tif_size);\n",
      "\n",
      "\t/*\n",
      "         * Clean up custom fields.\n",
      "         */\n",
      "\tif (tif->tif_fields && tif->tif_nfields > 0) {\n",
      "\t\tuint32_t i;\n",
      "\n",
      "\t\tfor (i = 0; i < tif->tif_nfields; i++) {\n",
      "\t\t\tTIFFField *fld = tif->tif_fields[i];\n",
      "\t\t\tif (fld->field_name != NULL) {\n",
      "\t\t\t\tif (fld->field_bit == FIELD_CUSTOM &&\n",
      "\t\t\t\t\tstrncmp(\"Tag \", fld->field_name, 4) == 0) {\n",
      "\t\t\t\t\t_TIFFfree(fld->field_name);\n",
      "\t\t\t\t\t_TIFFfree(fld);\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\n",
      "\t\t_TIFFfree(tif->tif_fields);\n",
      "\t}\n",
      "\n",
      "        if (tif->tif_nfieldscompat > 0) {\n",
      "                uint32_t i;\n",
      "\n",
      "                for (i = 0; i < tif->tif_nfieldscompat; i++) {\n",
      "                        if (tif->tif_fieldscompat[i].allocated_size)\n",
      "                                _TIFFfree(tif->tif_fieldscompat[i].fields);\n",
      "                }\n",
      "                _TIFFfree(tif->tif_fieldscompat);\n",
      "        }\n",
      "\n",
      "\t_TIFFfree(tif);\n",
      "}\"\n",
      "\n",
      "Code Snippet 2: \"void\n",
      "TIFFClose(TIFF* tif)\n",
      "{\n",
      "\tTIFFCloseProc closeproc = tif->tif_closeproc;\n",
      "\tthandle_t fd = tif->tif_clientdata;\n",
      "\n",
      "\tTIFFCleanup(tif);\n",
      "\t(void) (*closeproc)(fd);\n",
      "}\"\n",
      "\n",
      "Note that the following lines from the first code snippet have a high priority to be in the final modified code:\n",
      "\n",
      "Lines separated by /~/ : \"{'deleted_lines': ['\\t\\t\\t\\t\\tstrncmp(\"Tag \", fld->field_name, 4) == 0) {'], 'added_lines': ['\\t\\t\\t\\t\\t/* catuion: tif_fields[i] must not be the beginning of a fields-array.', '\\t\\t\\t\\t\\t *          Otherwise the following tags are also freed with the first free().', '\\t\\t\\t\\t\\t */', '\\t\\t\\t\\t\\tTIFFFieldIsAnonymous(fld)) {']}\"\n",
      "\n",
      "Put the generated code inside ```C ```. (Do not include comments)\n",
      "\n",
      "assistant\n",
      "����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������\n",
      "start_index\n",
      "2340\n",
      "end_index\n",
      "2341\n",
      "\n",
      "code\n",
      "Success!\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "\n",
      "Here are two code snippets specified below, modify code snippet No.2 in a way that it includes the logic of code No.1:\n",
      "Code Snippet 1: \"bool MessageReceiver::proc_Submsg_Data(\n",
      "        CDRMessage_t* msg,\n",
      "        SubmessageHeader_t* smh,\n",
      "        EntityId_t& writerID) const\n",
      "{\n",
      "    eprosima::shared_lock<eprosima::shared_mutex> guard(mtx_);\n",
      "\n",
      "    //READ and PROCESS\n",
      "    if (smh->submessageLength < RTPSMESSAGE_DATA_MIN_LENGTH)\n",
      "    {\n",
      "        EPROSIMA_LOG_INFO(RTPS_MSG_IN, IDSTRING \"Too short submessage received, ignoring\");\n",
      "        return false;\n",
      "    }\n",
      "    //Fill flags bool values\n",
      "    bool endiannessFlag = (smh->flags & BIT(0)) != 0;\n",
      "    bool inlineQosFlag = (smh->flags & BIT(1)) != 0;\n",
      "    bool dataFlag = (smh->flags & BIT(2)) != 0;\n",
      "    bool keyFlag = (smh->flags & BIT(3)) != 0;\n",
      "    if (keyFlag && dataFlag)\n",
      "    {\n",
      "        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Message received with Data and Key Flag set, ignoring\");\n",
      "        return false;\n",
      "    }\n",
      "\n",
      "    //Assign message endianness\n",
      "    if (endiannessFlag)\n",
      "    {\n",
      "        msg->msg_endian = LITTLEEND;\n",
      "    }\n",
      "    else\n",
      "    {\n",
      "        msg->msg_endian = BIGEND;\n",
      "    }\n",
      "\n",
      "    //Extra flags don't matter now. Avoid those bytes\n",
      "    msg->pos += 2;\n",
      "\n",
      "    bool valid = true;\n",
      "    int16_t octetsToInlineQos = 0;\n",
      "    valid &= CDRMessage::readInt16(msg, &octetsToInlineQos); //it should be 16 in this implementation\n",
      "\n",
      "    //reader and writer ID\n",
      "    RTPSReader* first_reader = nullptr;\n",
      "    EntityId_t readerID;\n",
      "    valid &= CDRMessage::readEntityId(msg, &readerID);\n",
      "\n",
      "    //WE KNOW THE READER THAT THE MESSAGE IS DIRECTED TO SO WE LOOK FOR IT:\n",
      "    if (!willAReaderAcceptMsgDirectedTo(readerID, first_reader))\n",
      "    {\n",
      "        return false;\n",
      "    }\n",
      "\n",
      "    //FOUND THE READER.\n",
      "    //We ask the reader for a cachechange to store the information.\n",
      "    CacheChange_t ch;\n",
      "    ch.kind = ALIVE;\n",
      "    ch.writerGUID.guidPrefix = source_guid_prefix_;\n",
      "    valid &= CDRMessage::readEntityId(msg, &ch.writerGUID.entityId);\n",
      "\n",
      "    writerID = ch.writerGUID.entityId;\n",
      "\n",
      "    //Get sequence number\n",
      "    valid &= CDRMessage::readSequenceNumber(msg, &ch.sequenceNumber);\n",
      "\n",
      "    if (!valid)\n",
      "    {\n",
      "        return false;\n",
      "    }\n",
      "\n",
      "    if (ch.sequenceNumber <= SequenceNumber_t())\n",
      "    {\n",
      "        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Invalid message received, bad sequence Number\");\n",
      "        return false;\n",
      "    }\n",
      "\n",
      "    //Jump ahead if more parameters are before inlineQos (not in this version, maybe if further minor versions.)\n",
      "    if (octetsToInlineQos > RTPSMESSAGE_OCTETSTOINLINEQOS_DATASUBMSG)\n",
      "    {\n",
      "        msg->pos += (octetsToInlineQos - RTPSMESSAGE_OCTETSTOINLINEQOS_DATASUBMSG);\n",
      "        if (msg->pos > msg->length)\n",
      "        {\n",
      "            EPROSIMA_LOG_WARNING(RTPS_MSG_IN,\n",
      "                    IDSTRING \"Invalid jump through msg, msg->pos \" << msg->pos << \" > msg->length \" << msg->length);\n",
      "            return false;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    uint32_t inlineQosSize = 0;\n",
      "\n",
      "    if (inlineQosFlag)\n",
      "    {\n",
      "        if (!ParameterList::updateCacheChangeFromInlineQos(ch, msg, inlineQosSize))\n",
      "        {\n",
      "            EPROSIMA_LOG_INFO(RTPS_MSG_IN, IDSTRING \"SubMessage Data ERROR, Inline Qos ParameterList error\");\n",
      "            return false;\n",
      "        }\n",
      "        ch.inline_qos.data = &msg->buffer[msg->pos - inlineQosSize];\n",
      "        ch.inline_qos.max_size = inlineQosSize;\n",
      "        ch.inline_qos.length = inlineQosSize;\n",
      "        ch.inline_qos.encapsulation = endiannessFlag ? PL_CDR_LE : PL_CDR_BE;\n",
      "        ch.inline_qos.pos = 0;\n",
      "    }\n",
      "\n",
      "    if (dataFlag || keyFlag)\n",
      "    {\n",
      "        uint32_t payload_size;\n",
      "        payload_size = smh->submessageLength -\n",
      "                (RTPSMESSAGE_DATA_EXTRA_INLINEQOS_SIZE + octetsToInlineQos + inlineQosSize);\n",
      "\n",
      "        if (dataFlag)\n",
      "        {\n",
      "            uint32_t next_pos = msg->pos + payload_size;\n",
      "            if (msg->length >= next_pos && payload_size > 0)\n",
      "            {\n",
      "                ch.serializedPayload.data = &msg->buffer[msg->pos];\n",
      "                ch.serializedPayload.length = payload_size;\n",
      "                ch.serializedPayload.max_size = payload_size;\n",
      "                msg->pos = next_pos;\n",
      "            }\n",
      "            else\n",
      "            {\n",
      "                EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Serialized Payload value invalid or larger than maximum allowed size\"\n",
      "                        \"(\" << payload_size << \"/\" << (msg->length - msg->pos) << \")\");\n",
      "                return false;\n",
      "            }\n",
      "        }\n",
      "        else if (keyFlag)\n",
      "        {\n",
      "            if (payload_size <= 0)\n",
      "            {\n",
      "                EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Serialized Payload value invalid (\" << payload_size << \")\");\n",
      "                return false;\n",
      "            }\n",
      "\n",
      "            if (payload_size <= PARAMETER_KEY_HASH_LENGTH)\n",
      "            {\n",
      "                memcpy(ch.instanceHandle.value, &msg->buffer[msg->pos], payload_size);\n",
      "            }\n",
      "            else\n",
      "            {\n",
      "                EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Ignoring Serialized Payload for too large key-only data (\" <<\n",
      "                        payload_size << \")\");\n",
      "            }\n",
      "            msg->pos += payload_size;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    // Set sourcetimestamp\n",
      "    if (have_timestamp_)\n",
      "    {\n",
      "        ch.sourceTimestamp = timestamp_;\n",
      "    }\n",
      "\n",
      "    EPROSIMA_LOG_INFO(RTPS_MSG_IN, IDSTRING \"from Writer \" << ch.writerGUID << \"; possible RTPSReader entities: \" <<\n",
      "            associated_readers_.size());\n",
      "\n",
      "    //Look for the correct reader to add the change\n",
      "    process_data_message_function_(readerID, ch);\n",
      "\n",
      "    IPayloadPool* payload_pool = ch.payload_owner();\n",
      "    if (payload_pool)\n",
      "    {\n",
      "        payload_pool->release_payload(ch);\n",
      "    }\n",
      "\n",
      "    //TODO(Ricardo) If an exception is thrown (ex, by fastcdr), these lines are not executed -> segmentation fault\n",
      "    ch.serializedPayload.data = nullptr;\n",
      "    ch.inline_qos.data = nullptr;\n",
      "\n",
      "    EPROSIMA_LOG_INFO(RTPS_MSG_IN, IDSTRING \"Sub Message DATA processed\");\n",
      "    return true;\n",
      "}\"\n",
      "\n",
      "Code Snippet 2: \"bool MessageReceiver::proc_Submsg_InfoSRC(\n",
      "        CDRMessage_t* msg,\n",
      "        SubmessageHeader_t* smh)\n",
      "{\n",
      "    std::lock_guard<eprosima::shared_mutex> guard(mtx_);\n",
      "\n",
      "    bool endiannessFlag = (smh->flags & BIT(0)) != 0;\n",
      "    //bool timeFlag = smh->flags & BIT(1) ? true : false;\n",
      "    //Assign message endianness\n",
      "    if (endiannessFlag)\n",
      "    {\n",
      "        msg->msg_endian = LITTLEEND;\n",
      "    }\n",
      "    else\n",
      "    {\n",
      "        msg->msg_endian = BIGEND;\n",
      "    }\n",
      "    if (smh->submessageLength == INFO_SRC_SUBMSG_LENGTH)\n",
      "    {\n",
      "        //AVOID FIRST 4 BYTES:\n",
      "        msg->pos += 4;\n",
      "        CDRMessage::readOctet(msg, &source_version_.m_major);\n",
      "        CDRMessage::readOctet(msg, &source_version_.m_minor);\n",
      "        CDRMessage::readData(msg, &source_vendor_id_[0], 2);\n",
      "        CDRMessage::readData(msg, source_guid_prefix_.value, GuidPrefix_t::size);\n",
      "        EPROSIMA_LOG_INFO(RTPS_MSG_IN, IDSTRING \"SRC RTPSParticipant is now: \" << source_guid_prefix_);\n",
      "        return true;\n",
      "    }\n",
      "    return false;\n",
      "}\"\n",
      "\n",
      "Note that the following lines from the first code snippet have a high priority to be in the final modified code:\n",
      "\n",
      "Lines separated by /~/ : \"{'deleted_lines': [], 'added_lines': ['                ch.serializedPayload.data = nullptr;', '                ch.inline_qos.data = nullptr;', '                ch.serializedPayload.data = nullptr;', '                ch.inline_qos.data = nullptr;']}\"\n",
      "\n",
      "Put the generated code inside ```C ```. (Do not include comments)\n",
      "\n",
      "assistant\n",
      "����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������\n",
      "start_index\n",
      "7258\n",
      "end_index\n",
      "7259\n",
      "\n",
      "code\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "\n",
      "Here are two code snippets specified below, modify code snippet No.2 in a way that it includes the logic of code No.1:\n",
      "Code Snippet 1: \"static void syborg_virtio_writel(void *opaque, target_phys_addr_t offset,\n",
      "                                 uint32_t value)\n",
      "{\n",
      "    SyborgVirtIOProxy *s = opaque;\n",
      "    VirtIODevice *vdev = s->vdev;\n",
      "\n",
      "    DPRINTF(\"writel 0x%x = 0x%x\\n\", (int)offset, value);\n",
      "    if (offset >= SYBORG_VIRTIO_CONFIG) {\n",
      "        return virtio_config_writel(vdev, offset - SYBORG_VIRTIO_CONFIG,\n",
      "                                    value);\n",
      "    }\n",
      "    switch (offset >> 2) {\n",
      "    case SYBORG_VIRTIO_GUEST_FEATURES:\n",
      "        if (vdev->set_features)\n",
      "            vdev->set_features(vdev, value);\n",
      "        vdev->guest_features = value;\n",
      "        break;\n",
      "    case SYBORG_VIRTIO_QUEUE_BASE:\n",
      "        if (value == 0)\n",
      "            virtio_reset(vdev);\n",
      "        else\n",
      "            virtio_queue_set_addr(vdev, vdev->queue_sel, value);\n",
      "        break;\n",
      "    case SYBORG_VIRTIO_QUEUE_SEL:\n",
      "        if (value < VIRTIO_PCI_QUEUE_MAX)\n",
      "            vdev->queue_sel = value;\n",
      "        break;\n",
      "    case SYBORG_VIRTIO_QUEUE_NOTIFY:\n",
      "        virtio_queue_notify(vdev, value);\n",
      "        break;\n",
      "    case SYBORG_VIRTIO_STATUS:\n",
      "        virtio_set_status(vdev, value & 0xFF);\n",
      "        if (vdev->status == 0)\n",
      "            virtio_reset(vdev);\n",
      "        break;\n",
      "    case SYBORG_VIRTIO_INT_ENABLE:\n",
      "        s->int_enable = value;\n",
      "        virtio_update_irq(vdev);\n",
      "        break;\n",
      "    case SYBORG_VIRTIO_INT_STATUS:\n",
      "        vdev->isr &= ~value;\n",
      "        virtio_update_irq(vdev);\n",
      "        break;\n",
      "    default:\n",
      "        BADF(\"Bad write offset 0x%x\\n\", (int)offset);\n",
      "        break;\n",
      "    }\n",
      "}\"\n",
      "\n",
      "Code Snippet 2: \"static unsigned syborg_virtio_get_features(void *opaque)\n",
      "{\n",
      "    SyborgVirtIOProxy *proxy = opaque;\n",
      "    return proxy->host_features;\n",
      "}\"\n",
      "\n",
      "Note that the following lines from the first code snippet have a high priority to be in the final modified code:\n",
      "\n",
      "Lines separated by /~/ : \"{'deleted_lines': ['        virtio_queue_notify(vdev, value);'], 'added_lines': ['        if (value < VIRTIO_PCI_QUEUE_MAX) {', '            virtio_queue_notify(vdev, value);', '        }']}\"\n",
      "\n",
      "Put the generated code inside ```C ```. (Do not include comments)\n",
      "\n",
      "assistant\n",
      " assistant\n",
      "\n",
      "Assistant: Here is the modified code snippet 2:\n",
      "\n",
      "```C\n",
      "static unsigned syborg_virtio_get_features(void *opaque)\n",
      "{\n",
      "    SyborgVirtIOProxy *proxy = opaque;\n",
      "    return proxy->host_features;\n",
      "}\n",
      "```\n",
      "\n",
      "Note that the following lines from the first code snippet have a high priority to be in the final modified code:\n",
      "\n",
      "Lines separated by /~/ : \n",
      "{'deleted_lines': ['        virtio_queue_notify(vdev, value);'], 'added_lines': ['        if (value < VIRTIO_PCI_QUEUE_MAX) {', '            virtio_queue_notify(vdev, value);', '        }']}\n",
      "start_index\n",
      "2190\n",
      "end_index\n",
      "2191\n",
      "\n",
      "code\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from rag import SearchItem\n",
    "# from chat import ConcurrencyUtils as cu\n",
    "\n",
    "def get_index(search_item: SearchItem):\n",
    "    return str(search_item.best)\n",
    "\n",
    "\n",
    "def get_vul(search_item: SearchItem):\n",
    "    best_target_index = search_item.best\n",
    "    vul_record = vul_df[vul_df['file_path'] == best_target_index]\n",
    "    return str(vul_record['func_before'].values[0])\n",
    "\n",
    "def get_fixed_vul(search_item: SearchItem):\n",
    "    best_target_index = search_item.best\n",
    "    vul_record = vul_df[vul_df['file_path'] == best_target_index]\n",
    "    return str(vul_record['func'].values[0])\n",
    "\n",
    "# def get_vul_lines(search_item: SearchItem):\n",
    "#     best_target_index = search_item.best\n",
    "#     vul_record = vul_df[vul_df['file_path'] == best_target_index]\n",
    "#     flaw_lines = str(vul_record['diff_line_info'].values[0]).strip()\n",
    "#     if len(flaw_lines) < 5:\n",
    "#         raise Exception(f\"Invalid Vul_lines: {flaw_lines}\")\n",
    "#     return flaw_lines\n",
    "def get_vul_lines(search_item: SearchItem):\n",
    "    best_target_index = search_item.best\n",
    "    vul_record = vul_df[vul_df['file_path'] == best_target_index]\n",
    "\n",
    "    # Debugging step: Print matched rows\n",
    "    # print(f\"Matching records for {best_target_index}:\")\n",
    "    # print(vul_record)\n",
    "\n",
    "    # Check if record exists\n",
    "    if vul_record.empty:\n",
    "        raise Exception(f\"No matching record found for file_path: {best_target_index}\")\n",
    "\n",
    "    # Check if `diff_line_info` exists\n",
    "    if \"diff_line_info\" not in vul_record.columns:\n",
    "        raise Exception(f\"Missing `diff_line_info` column in vul_df!\")\n",
    "\n",
    "    # Extract flaw lines\n",
    "    flaw_lines = vul_record['diff_line_info'].values[0]\n",
    "\n",
    "    # Handle missing or empty flaw_lines\n",
    "    if flaw_lines is None or str(flaw_lines).strip() == \"\":\n",
    "        raise Exception(f\"Missing or empty `diff_line_info` for: {best_target_index}\")\n",
    "\n",
    "    return str(flaw_lines).strip()\n",
    "\n",
    "# def get_clean_megavul(search_item: SearchItem):\n",
    "#     with open(f\"./../devign_code/{search_item.searchItemId}\", 'r') as file:\n",
    "#         clean_item = file.read()\n",
    "#     return clean_item\n",
    "\n",
    "def get_clean_megavul(search_item: SearchItem):\n",
    "    best_target_index = search_item.best\n",
    "    return str(clean_df[clean_df['file_path'] == best_target_index]['func'].values[0])\n",
    "\n",
    "# def get_clean_megavul(search_item: SearchItem):\n",
    "#     # Search for the function by matching `searchItemId` with the `file_path` key\n",
    "#     for item in clean_json_data:\n",
    "#         if item.get(\"file_path\") == search_item.searchItemId:\n",
    "#             return item.get(\"func\", None)  # Return function content if found\n",
    "\n",
    "#     return None  # Return None if not found\n",
    "\n",
    "# Formulator Functions that take a search result and populates a prompt template\n",
    "\n",
    "def get_injection_strategy_devign(search_item: SearchItem): # the Injection strategy while the clean's come from devign\n",
    "    clean_item = get_clean_megavul(search_item)\n",
    "    vul_code = get_vul(search_item)\n",
    "    flaw_lines = get_vul_lines(search_item)\n",
    "    return PromptUtils.get_full_prompt(vul_code, clean_item, flaw_lines)\n",
    "\n",
    "\n",
    "# def get_extension_strategy_devign(search_item: SearchItem):\n",
    "#     clean_item = get_clean_megavul(search_item)\n",
    "#     vul_code = get_vul(search_item)\n",
    "#     flaw_lines = get_vul_lines(search_item)\n",
    "#     return PromptUtils.get_ext_wl_prompt(clean_item, vul_code, flaw_lines)\n",
    "\n",
    "# def get_mutation_strategy(search_item: SearchItem):\n",
    "#     vul_code = get_vul(search_item)\n",
    "#     flaw_lines = get_vul_lines(search_item)\n",
    "#     return PromptUtils.get_mutation_prompt(vul_code, flaw_lines)\n",
    "\n",
    "\n",
    "# Generator Phase (can send concurrent requests)\n",
    "indices, vuls, cleans, vul_lines, generated = ConcurrencyUtils.concurrent_prompter(\n",
    "    prompt_creator_from_searchItem=get_injection_strategy_devign,\n",
    "    index_retreiver=get_index,\n",
    "    vul_retriever=get_vul,\n",
    "    clean_retriever=get_clean_megavul,\n",
    "    vul_lines_retriever=get_vul_lines,\n",
    "    search_results=search_results,\n",
    "    llm=ch, target=6000, max_workers=8, is_all=False, resume_from_dataframe=None)  # for code Qwen set workers to 1 as there's only one model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NBOcsw1-PkTz"
   },
   "outputs": [],
   "source": [
    "# save the results of the Generator\n",
    "df_result = pd.DataFrame({'vul': vuls, 'vul_lines': vul_lines, 'clean': cleans, 'generated': generated, 'idx':indices})\n",
    "df_result.to_json(f\"./generated/6k-devign-injection-clusterfair.jsonl\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "005d0341ea6641f6a4791478ed314311": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "03b6ccb57b9040aab108fcdbc4527111": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07b53d4510e14e27aadf6f243da18aaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ec313b39f2542909da5117f9c5eb230": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19fcc10394cf4802a1588998c0452c90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e9438d9af8e4f739641151ab3653ebb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26a5990dd12d4c069dfc4153073d00c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2740b36a48a942c79c00d396b393a188": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "278a282d37d6434f90c7fd6680c06b09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a3c6a7d26c54985b53fba9bd4ce3a21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3cb027ce1734479db2a68e1c05d8622c",
       "IPY_MODEL_3f2c38f76ede4ab6b2fd41028fa88323",
       "IPY_MODEL_5453f349917242248efdbb33c6ce986f"
      ],
      "layout": "IPY_MODEL_ea000cf25e234dc18e6c6adf800ff626"
     }
    },
    "2b26301a4aeb4b15b325f2bf5c9bd09f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8eafb62d497c4d7aaf5c633474d02da0",
       "IPY_MODEL_f18b5e7509d74e86956a3bc266289132",
       "IPY_MODEL_63d7d35d333742c5992beea2d1c273c8"
      ],
      "layout": "IPY_MODEL_4f8244c8ba5a4184a4c7096ffdde7250"
     }
    },
    "2d1f33fbdfc04b4f87dfdb30bca3225c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7f7febeb4ae414faa698e665adbc32f",
      "max": 7031645,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f39d2c669f9d41e8af6de6ab050879a2",
      "value": 7031645
     }
    },
    "2e11cd13e59d4e1883abfaab31060d54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fff5bc8fa634856b9f14952e558ffcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_768e58e484c042a0944b5ac19e83665b",
      "placeholder": "​",
      "style": "IPY_MODEL_557a9427351b45ba9545ce332d40b665",
      "value": "tokenizer.json: 100%"
     }
    },
    "306dceeea0784de4b7e88f4cde9cf521": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36e2b042b4bc4b4b9c9a77eb9c5b3b44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d1e55069f9e545749f3971d944bccfd6",
       "IPY_MODEL_dfa350f887994bc48b66119fc6486881",
       "IPY_MODEL_828f75b3426d4ff189509cd0a842e438"
      ],
      "layout": "IPY_MODEL_cb36422a241147c99777a6a99ae8c3d9"
     }
    },
    "385697c4bd3f428885c6bbd8d03ccbf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3adb51dbab0b4ca38e069f7b9c8c2a5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cb027ce1734479db2a68e1c05d8622c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edce3e0fcde443d48ff517db3028c803",
      "placeholder": "​",
      "style": "IPY_MODEL_984f83669ba14f1d9c07a3036eecc847",
      "value": "generation_config.json: 100%"
     }
    },
    "3ecd955e6d74438ba39e8ab3ce6e5520": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_968cd6fbea5244189f7b971143994f35",
      "placeholder": "​",
      "style": "IPY_MODEL_fe62d8520c0f44369928277280c2606a",
      "value": " 3.09G/3.09G [00:21&lt;00:00, 226MB/s]"
     }
    },
    "3f2c38f76ede4ab6b2fd41028fa88323": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d3456166f3e4242b15e8f547410ee35",
      "max": 117,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af680cda0b5b48a4adfc916f13dd8e9c",
      "value": 117
     }
    },
    "4b038a9843654347bd300e1945408ebe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d3456166f3e4242b15e8f547410ee35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f8244c8ba5a4184a4c7096ffdde7250": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5453f349917242248efdbb33c6ce986f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ec313b39f2542909da5117f9c5eb230",
      "placeholder": "​",
      "style": "IPY_MODEL_b7267a5741064dbeba307399be30f02b",
      "value": " 117/117 [00:00&lt;00:00, 10.1kB/s]"
     }
    },
    "557a9427351b45ba9545ce332d40b665": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bfd08271f984f06899939df9f7c478a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5dcf1330e1074ff08c3e866b8e68eb07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f886e342b814f478e7e0da656a49bc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa0284c9ccd64058926653c2d1ae50f9",
       "IPY_MODEL_6bcee50339cf42acbadc051a682ec1c8",
       "IPY_MODEL_c9cc357c3642493d832e0987086343e4"
      ],
      "layout": "IPY_MODEL_dc99fe811abf475d80cd622f90b9b6c5"
     }
    },
    "61bc6ea7c468421690dd0bc59c96f05d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62fd80d356054bd09e609e37b0975340": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "639acc24a01f49be8fabf0c76148bd30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3efa7c6655140a7b342b99a88c1c05c",
      "placeholder": "​",
      "style": "IPY_MODEL_778d34104a954257b9a713e7f4f696ce",
      "value": " 7.03M/7.03M [00:00&lt;00:00, 67.7MB/s]"
     }
    },
    "63a36ff6ae1544219da744271760dea1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2fff5bc8fa634856b9f14952e558ffcd",
       "IPY_MODEL_2d1f33fbdfc04b4f87dfdb30bca3225c",
       "IPY_MODEL_639acc24a01f49be8fabf0c76148bd30"
      ],
      "layout": "IPY_MODEL_62fd80d356054bd09e609e37b0975340"
     }
    },
    "63d7d35d333742c5992beea2d1c273c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_278a282d37d6434f90c7fd6680c06b09",
      "placeholder": "​",
      "style": "IPY_MODEL_f877f96eb82d40039b02bd51ea308c17",
      "value": " 2.78M/2.78M [00:00&lt;00:00, 9.55MB/s]"
     }
    },
    "661a72e797354a1192cef9fac7638151": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6890f2aa23334e55b681d3b1d57e878d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "697593ee9ee74e779d489fe0d21c31e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6bcee50339cf42acbadc051a682ec1c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26a5990dd12d4c069dfc4153073d00c7",
      "max": 660,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_697593ee9ee74e779d489fe0d21c31e9",
      "value": 660
     }
    },
    "70ddb3252c5944f89ecf242c3b0d63f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "768e58e484c042a0944b5ac19e83665b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "778d34104a954257b9a713e7f4f696ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c946a3769cf4b91b65760a7d8822fb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "828f75b3426d4ff189509cd0a842e438": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d9f28ac464a4c6395ee7192b519d040",
      "placeholder": "​",
      "style": "IPY_MODEL_1e9438d9af8e4f739641151ab3653ebb",
      "value": " 1.67M/1.67M [00:00&lt;00:00, 6.08MB/s]"
     }
    },
    "8d9f28ac464a4c6395ee7192b519d040": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8eafb62d497c4d7aaf5c633474d02da0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5dcf1330e1074ff08c3e866b8e68eb07",
      "placeholder": "​",
      "style": "IPY_MODEL_07b53d4510e14e27aadf6f243da18aaf",
      "value": "vocab.json: 100%"
     }
    },
    "95bbcaddee5b46f6a8a4a003dbb4de48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eed2180e1e18432da769369fb0d5cd9f",
       "IPY_MODEL_fbc4ffed7274465ba6e9955f881e03e6",
       "IPY_MODEL_3ecd955e6d74438ba39e8ab3ce6e5520"
      ],
      "layout": "IPY_MODEL_ae843c1e0d5a4d41af67f9ad20886b3e"
     }
    },
    "968cd6fbea5244189f7b971143994f35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "984f83669ba14f1d9c07a3036eecc847": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa0284c9ccd64058926653c2d1ae50f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b038a9843654347bd300e1945408ebe",
      "placeholder": "​",
      "style": "IPY_MODEL_661a72e797354a1192cef9fac7638151",
      "value": "config.json: 100%"
     }
    },
    "ae843c1e0d5a4d41af67f9ad20886b3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af680cda0b5b48a4adfc916f13dd8e9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7267a5741064dbeba307399be30f02b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b7f7febeb4ae414faa698e665adbc32f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba5913acc1df49b48a670924be88e58e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9cc357c3642493d832e0987086343e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfd11c763f8a4f68bc9379815bd5c38c",
      "placeholder": "​",
      "style": "IPY_MODEL_6890f2aa23334e55b681d3b1d57e878d",
      "value": " 660/660 [00:00&lt;00:00, 58.4kB/s]"
     }
    },
    "cb36422a241147c99777a6a99ae8c3d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1e55069f9e545749f3971d944bccfd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_306dceeea0784de4b7e88f4cde9cf521",
      "placeholder": "​",
      "style": "IPY_MODEL_385697c4bd3f428885c6bbd8d03ccbf3",
      "value": "merges.txt: 100%"
     }
    },
    "dc99fe811abf475d80cd622f90b9b6c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df5a6e83d60843969d8cca9c4f669ee3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfa350f887994bc48b66119fc6486881": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3adb51dbab0b4ca38e069f7b9c8c2a5b",
      "max": 1671839,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fd58db648108455aaec268f590906007",
      "value": 1671839
     }
    },
    "dfd11c763f8a4f68bc9379815bd5c38c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5c6d4842ad54793a259c2cdd53403fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61bc6ea7c468421690dd0bc59c96f05d",
      "placeholder": "​",
      "style": "IPY_MODEL_19fcc10394cf4802a1588998c0452c90",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "e8e1ea806614495182385b939174c8e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03b6ccb57b9040aab108fcdbc4527111",
      "max": 7308,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7c946a3769cf4b91b65760a7d8822fb1",
      "value": 7308
     }
    },
    "e8f10149ed324d89a883b6876c012d2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ea000cf25e234dc18e6c6adf800ff626": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb8050759f214d9abf3a953d40772bda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e5c6d4842ad54793a259c2cdd53403fa",
       "IPY_MODEL_e8e1ea806614495182385b939174c8e3",
       "IPY_MODEL_f244532039244f0ca83d0ac32c52bdda"
      ],
      "layout": "IPY_MODEL_ba5913acc1df49b48a670924be88e58e"
     }
    },
    "edce3e0fcde443d48ff517db3028c803": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eed2180e1e18432da769369fb0d5cd9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df5a6e83d60843969d8cca9c4f669ee3",
      "placeholder": "​",
      "style": "IPY_MODEL_2740b36a48a942c79c00d396b393a188",
      "value": "model.safetensors: 100%"
     }
    },
    "f18b5e7509d74e86956a3bc266289132": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70ddb3252c5944f89ecf242c3b0d63f9",
      "max": 2776833,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fed0215cd5fb4aa795fa4eb4c6e882fa",
      "value": 2776833
     }
    },
    "f244532039244f0ca83d0ac32c52bdda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e11cd13e59d4e1883abfaab31060d54",
      "placeholder": "​",
      "style": "IPY_MODEL_005d0341ea6641f6a4791478ed314311",
      "value": " 7.31k/7.31k [00:00&lt;00:00, 545kB/s]"
     }
    },
    "f39d2c669f9d41e8af6de6ab050879a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f3efa7c6655140a7b342b99a88c1c05c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f877f96eb82d40039b02bd51ea308c17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fbc4ffed7274465ba6e9955f881e03e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bfd08271f984f06899939df9f7c478a",
      "max": 3087467144,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e8f10149ed324d89a883b6876c012d2e",
      "value": 3087467144
     }
    },
    "fd58db648108455aaec268f590906007": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe62d8520c0f44369928277280c2606a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fed0215cd5fb4aa795fa4eb4c6e882fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
