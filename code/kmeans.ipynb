{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda clean --all\n",
    "# !conda update -n base -c defaults conda\n",
    "\n",
    "# CUDA Toolkit 11.3\n",
    "# https://developer.nvidia.com/cuda-11.3.0-download-archive?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exe_local\n",
    "#https://pytorch.org/get-started/previous-versions/\n",
    "\n",
    "# !conda create --name vulscriber-cluster-env python=3.8\n",
    "# !conda install pytorch==1.10.0 torchvision==0.11.1 torchaudio==0.10.0 cudatoolkit=11.3 -c pytorch\n",
    "# !conda install transformers pandas scikit-learn\n",
    "\n",
    "# https://stackoverflow.com/questions/75242037/failed-to-import-transformers-onnx-config\n",
    "# !conda install -c conda-forge sentence-transformers\n",
    "# !conda install Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON & Convert to DataFrame\n",
    "filename = r\"C:\\Users\\Administrator\\Downloads\\mapr\\VulScribeR-main\\dataset\\megavul_simple.json\"\n",
    "with open(filename, \"r\") as f:\n",
    "    json_data = json.load(f)\n",
    "mega_vul_df = pd.DataFrame(json_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encode vectors\n",
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "# import gc\n",
    "\n",
    "# BATCH_SIZE = 128  \n",
    "# SAVE_PATH = \"encoded_vectors.pkl\"  # Dùng pickle thay vì JSON\n",
    "# SAVE_EVERY = 50  \n",
    "\n",
    "# torch.backends.cudnn.benchmark = True  \n",
    "\n",
    "# # Tải checkpoint nếu có\n",
    "# try:\n",
    "#     with open(SAVE_PATH, \"rb\") as f:\n",
    "#         index_to_vector_map = pickle.load(f)\n",
    "#         print(f\"✅ Resume từ checkpoint: {len(index_to_vector_map)} vectors\")\n",
    "# except FileNotFoundError:\n",
    "#     index_to_vector_map = {}\n",
    "\n",
    "# # Chuẩn bị danh sách các mẫu chưa encode trước vòng lặp\n",
    "# code_samples = [(i, str(row[\"func\"])) for i, row in mega_vul_df.iterrows() if str(row[\"func\"]).strip()]\n",
    "# code_samples = [(i, code) for i, code in code_samples if i not in index_to_vector_map]  \n",
    "# total_samples = len(code_samples)\n",
    "\n",
    "# # Nếu tất cả đã encode, thoát sớm\n",
    "# if total_samples == 0:\n",
    "#     print(\"✅ Tất cả mẫu đã được encode!\")\n",
    "#     exit()\n",
    "\n",
    "# batch_count = 0  \n",
    "\n",
    "# for i in tqdm(range(0, total_samples, BATCH_SIZE), desc=\"Encoding...\"):\n",
    "#     batch_indices, batch_codes = zip(*code_samples[i : i + BATCH_SIZE])\n",
    "\n",
    "#     # Encode batch\n",
    "#     inputs = tokenizer(batch_codes, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "#     inputs = {k: v.to(\"cuda:0\", non_blocking=True) for k, v in inputs.items()}\n",
    "\n",
    "#     with torch.inference_mode(), torch.cuda.amp.autocast():\n",
    "#         outputs = model(**inputs)\n",
    "\n",
    "#     batch_vectors = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "#     # Lưu vào dict\n",
    "#     index_to_vector_map.update({idx: vec.tolist() for idx, vec in zip(batch_indices, batch_vectors)})\n",
    "\n",
    "#     batch_count += 1\n",
    "#     if batch_count % SAVE_EVERY == 0:  # Chỉ lưu mỗi 10 batch\n",
    "#         with open(SAVE_PATH, \"wb\") as f:\n",
    "#             pickle.dump(index_to_vector_map, f)\n",
    "\n",
    "#         torch.cuda.empty_cache()  \n",
    "#         gc.collect()\n",
    "\n",
    "# # Lưu lần cuối\n",
    "# with open(SAVE_PATH, \"wb\") as f:\n",
    "#     pickle.dump(index_to_vector_map, f)\n",
    "\n",
    "# print(f\"✅ Hoàn tất encoding! Đã lưu vào {SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load encodede vectors pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File pickle tải thành công! 353873\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = \"encoded_vectors.pkl\"\n",
    "\n",
    "try:\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    print(\"✅ File pickle tải thành công!\", len(data))\n",
    "except Exception as e:\n",
    "    print(\"❌ Lỗi khi tải file pickle:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chuẩn bị danh sách các mẫu chưa encode trước vòng lặp\n",
    "code_samples = [(i, str(row[\"func\"])) for i, row in mega_vul_df.iterrows() if str(row[\"func\"]).strip()]\n",
    "code_samples = [(i, code) for i, code in code_samples if i not in data]  \n",
    "total_samples = len(code_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã lấy được 353873 vectors từ pickle!\n"
     ]
    }
   ],
   "source": [
    "# print(type(data))\n",
    "# print(len(data))\n",
    "encoded_code_vectors = list(data.values())\n",
    "print(f\"✅ Đã lấy được {len(encoded_code_vectors)} vectors từ pickle!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\vulscriber-cluster-env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(encoded_code_vectors)\n",
    "\n",
    "# Get the cluster labels for each code piece\n",
    "cluster_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = './dataset/container_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "mega_vul_df['cluster'] = cluster_labels\n",
    "\n",
    "for cluster_number, group_df in mega_vul_df.groupby('cluster'):\n",
    "    file_name = os.path.join(output_dir, f'megavul_vuls_cls_{cluster_number}.jsonl')\n",
    "    group_df[['func', 'is_vul', 'diff_line_info', 'func_before']].to_json(file_name, orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅ Bạn chỉ encode các dòng có func, nhưng một số dòng có thể bị thiếu func:\n",
    "\n",
    "code_samples = [(i, str(row[\"func\"])) for i, row in mega_vul_df.iterrows() if str(row[\"func\"]).strip()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41918, 65107, 68454, 85557, 92837, 0]\n"
     ]
    }
   ],
   "source": [
    "arr = [0,0,0,0,0,0]\n",
    "for i in cluster_labels:\n",
    "    arr[i]+=1\n",
    "\n",
    "print(arr) # avg -> BIGVUL [1238, 1187, 1069, 1372, 3917, 0] order is [4,3,1,0,2] and kmeans indices are 0,1,2,3,4 for 5 clusters\n",
    "# MEGAVUL [41918, 65107, 68454, 85557, 92837, 0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vulscriber-cluster-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
